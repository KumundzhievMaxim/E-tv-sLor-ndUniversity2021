% general nuclear imaging
@Book{oftankonyv,
 author = {Berczi, Viktor and Karlinger, Kinga and Kári, Béla and Légrády, Dávid and Czifrus, Szabolcs},
 title = {Medical Imaging},
 publisher = {Semmelweis University, Faculty of Medicine, Department of Radiology, Nuclear Medical Center and Budapest University of Technology and Economics, Faculty of Natural Sciences, Institute of Nuclear Technique},
 year = {2019},
 address = {Budapest},
 isbn = {9789633130667}
}


@inproceedings{Jha2020,
   abstract = {Semantic image segmentation is the process of labeling each pixel of an image with its corresponding class. An encoder-decoder based approach, like U-Net and its variants, is a popular strategy for solving medical image segmentation tasks. To improve the performance of U-Net on various segmentation tasks, we propose a novel architecture called DoubleU-Net, which is a combination of two U-Net architectures stacked on top of each other. The first U-Net uses a pre-trained VGG-19 as the encoder, which has already learned features from ImageNet and can be transferred to another task easily. To capture more semantic information efficiently, we added another U-Net at the bottom. We also adopt Atrous Spatial Pyramid Pooling (ASPP) to capture contextual information within the network. We have evaluated DoubleU-Net using four medical segmentation datasets, covering various imaging modalities such as colonoscopy, dermoscopy, and microscopy. Experiments on the MICCAI 2015 segmentation challenge, the CVC-ClinicDB, the 2018 Data Science Bowl challenge, and the Lesion boundary segmentation datasets demonstrate that the DoubleU-Net outperforms U-Net and the baseline models. Moreover, DoubleU-Net produces more accurate segmentation masks, especially in the case of the CVC-ClinicDB and MICCAI 2015 segmentation challenge datasets, which have challenging images such as smaller and flat polyps. These results show the improvement over the existing U-Net model. The encouraging results, produced on various medical image segmentation datasets, show that DoubleU-Net can be used as a strong baseline for both medical image segmentation and cross-dataset evaluation testing to measure the generalizability of Deep Learning (DL) models.},
   author = {Debesh Jha and Michael A. Riegler and Dag Johansen and Pal Halvorsen and Havard D. Johansen},
   doi = {10.1109/CBMS49503.2020.00111},
   isbn = {9781728194295},
   issn = {10637125},
   journal = {Proceedings - IEEE Symposium on Computer-Based Medical Systems},
   keywords = {2018 Data Science Bowl,ASPP,CVC-ClinicDB,Convolutional neural network,DoubleU-Net,ETIS-Larib,Lesion boundary segmentation challenge,MICCAI 2015 segmentation,Semantic segmentation,U-Net},
   month = {7},
   pages = {558-564},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {DoubleU-Net: A deep convolutional neural network for medical image segmentation},
   volume = {2020-July},
   year = {2020},
}


@article{Ahmed2020,
   abstract = {Image segmentation is considered as a key research topic in the area of computer vision. It is pivotal in a broad range of real-life applications. Recently, the emergence of deep learning drives significant advancement in image segmentation; the developed systems are now capable of recognizing, segmenting, and classifying objects of specific interest in images. Generally, most of these techniques primarily focused on the asymmetric field of view or frontal view objects. This work explores widely used deep learning-based models for person segmentation using top view data set. The first model employed in this work is Fully Convolutional Neural Network (FCN) with Resnet-101 architecture. The network consists of a set of max-pooling and convolution layers to identify pixel-wise class labels and prediction of the mask. The second model is based on FCN called U-Net with Encoder-Decoder architecture. The encoder is mainly comprised of a contracting path, also called an encoder, which captures the context in the image and symmetric expanding path called decoder to enable accurate location. The third model used for top view person segmentation is a DeepLabV3 model also with encoder-decoder architecture. The encoder consists of trained Convolutional Neural Network (CNN) to encode feature maps of the input image. The decoder is used for up-sampling and reconstruction of output using important information extracted by the encoder. All segmentation models are firstly tested using pre-trained models (trained on frontal view data set). To improve the performance, these models are further trained using person data set captured from a top view. The output of all models consists of a segmented person in the top view images. The experimental results reveal the effectiveness and performance of segmentation models by achieving IoU of 83%, 84%, and 86% and mIoU of 80% 82% and 84% for FCN, U-Net, and DeepLabv3 respectively. Furthermore, the discussion is provided for output results with possible future guidelines.},
   author = {Imran Ahmed and Misbah Ahmad and Fakhri Alam Khan and Muhammad Asif},
   doi = {10.1109/ACCESS.2020.3011406},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {Deep learning,DeepLab,FCN,U-Net,semantic segmentation,top view person},
   pages = {136361-136373},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Comparison of deep-learning-based segmentation models: Using top view person images},
   volume = {8},
   year = {2020},
}


@Book{aarsvold2004emission,
 author = {Aarsvold, John},
 title = {Emission Tomography : the Fundamentals of Pet and Spect},
 publisher = {Elsevier},
 year = {2004},
 address = {Burlington},
 isbn = {9780080521879}
 }

@article{Jaszczak1981,
  doi = {10.1109/tns.1981.4331143},
  url = {https://doi.org/10.1109/tns.1981.4331143},
  year = {1981},
  month = feb,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {28},
  number = {1},
  pages = {69--80},
  author = {Ronald J. Jaszczak and R. Edward Coleman and Frank R. Whitehead},
  title = {Physical Factors Affecting Quantitative Measurements Using Camera-Based Single Photon Emission Computed Tomography (Spect)},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Kay1994,
  doi = {10.1177/096228029400300102},
  url = {https://doi.org/10.1177/096228029400300102},
  year = {1994},
  month = mar,
  publisher = {{SAGE} Publications},
  volume = {3},
  number = {1},
  pages = {5--21},
  author = {Jim Kay},
  title = {Statistical models for {PET} and {SPECT} data},
  journal = {Statistical Methods in Medical Research}
}

% monte carlo 
@book{Lux2018,
  doi = {10.1201/9781351074834},
  url = {https://doi.org/10.1201/9781351074834},
  year = {2018},
  month = may,
  publisher = {{CRC} Press},
  author = {Iv{\'{a}}n Lux and L{\'{a}}szl{\'{o}} Koblinger},
  title = {Monte Carlo Particle Transport Methods: Neutron and Photon Calculations}
}

@book{seco_monte_2016,
	address = {Boca Raton [etc.},
	title = {Monte {Carlo} techniques in radiation therapy},
	isbn = {9781138199903 9781466507920},
	language = {English},
	publisher = {CRC Press},
	author = {Seco, Joao and Verhaegen, Frank and {CRC Press}},
	year = {2016},
	note = {OCLC: 1000033162}
}

@Book{dupree2002a,
 author = {Dupree, Stephen},
 title = {A Monte Carlo Primer : a Practical Approach to Radiation Transport},
 publisher = {Springer US Imprint Springer},
 year = {2002},
 address = {Boston, MA},
 isbn = {978-1-4419-8491-3}
 }

% recon
@article{Shepp1974,
  doi = {10.1109/tns.1974.6499235},
  url = {https://doi.org/10.1109/tns.1974.6499235},
  year = {1974},
  month = jun,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {21},
  number = {3},
  pages = {21--43},
  author = {L. A. Shepp and B. F. Logan},
  title = {The Fourier reconstruction of a head section},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Shepp1982,
  doi = {10.1109/tmi.1982.4307558},
  url = {https://doi.org/10.1109/tmi.1982.4307558},
  year = {1982},
  month = oct,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {1},
  number = {2},
  pages = {113--122},
  author = {L. A. Shepp and Y. Vardi},
  title = {Maximum Likelihood Reconstruction for Emission Tomography},
  journal = {{IEEE} Transactions on Medical Imaging}
}

@article{Chornoboy1990,
  doi = {10.1109/42.52987},
  url = {https://doi.org/10.1109/42.52987},
  year = {1990},
  month = mar,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {9},
  number = {1},
  pages = {99--110},
  author = {E.S. Chornoboy and C.J. Chen and M.I. Miller and T.R. Miller and D.L. Snyder},
  title = {An evaluation of maximum likelihood reconstruction for {SPECT}},
  journal = {{IEEE} Transactions on Medical Imaging}
}

@article{Green1990,
  doi = {10.1109/42.52985},
  url = {https://doi.org/10.1109/42.52985},
  year = {1990},
  month = mar,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {9},
  number = {1},
  pages = {84--93},
  author = {P.J. Green},
  title = {Bayesian reconstructions from emission tomography data using a modified {EM} algorithm},
  journal = {{IEEE} Transactions on Medical Imaging}
}

@article{Green1990_2,
  doi = {10.1111/j.2517-6161.1990.tb01798.x},
  url = {https://doi.org/10.1111/j.2517-6161.1990.tb01798.x},
  year = {1990},
  month = jul,
  publisher = {Wiley},
  volume = {52},
  number = {3},
  pages = {443--452},
  author = {Peter J. Green},
  title = {On Use of the Em Algorithm for Penalized Likelihood Estimation},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)}
}

@article{Hudson1994,
  doi = {10.1109/42.363108},
  url = {https://doi.org/10.1109/42.363108},
  year = {1994},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {13},
  number = {4},
  pages = {601--609},
  author = {H.M. Hudson and R.S. Larkin},
  title = {Accelerated image reconstruction using ordered subsets of projection data},
  journal = {{IEEE} Transactions on Medical Imaging}
}

@article{DiBella1996,
  doi = {10.1109/23.552756},
  url = {https://doi.org/10.1109/23.552756},
  year = {1996},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {43},
  number = {6},
  pages = {3370--3376},
  author = {E.V.R. Di Bella and A.B. Barclay and R.L. Eisner and R.W. Schafer},
  title = {A comparison of rotation-based methods for iterative reconstruction algorithms},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Wallis1997,
  doi = {10.1109/42.552061},
  url = {https://doi.org/10.1109/42.552061},
  year = {1997},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {16},
  number = {1},
  pages = {118--123},
  author = {J.W. Wallis and T.R. Miller},
  title = {An optimal rotator for iterative reconstruction},
  journal = {{IEEE} Transactions on Medical Imaging}
}

@article{Kamphuis1997,
  doi = {10.1007/s002590050188},
  url = {https://doi.org/10.1007/s002590050188},
  year = {1997},
  month = dec,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {25},
  number = {1},
  pages = {8--18},
  author = {Chris Kamphuis and Freek J. Beekman and Peter P. van Rijk and Max A. Viergever},
  title = {Dual matrix ordered subsets reconstruction for accelerated 3D scatter compensation in single-photon emission tomography},
  journal = {European Journal of Nuclear Medicine and Molecular Imaging}
}

@article{Panin1999,
  doi = {10.1109/23.819305},
  url = {https://doi.org/10.1109/23.819305},
  year = {1999},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {46},
  number = {6},
  pages = {2202--2210},
  author = {V.Y. Panin and G.L. Zeng and G.T. Gullberg},
  title = {Total variation regulated {EM} algorithm [{SPECT} reconstruction]},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Persson2001,
  doi = {10.1016/s0168-9002(01)00962-7},
  url = {https://doi.org/10.1016/s0168-9002(01)00962-7},
  year = {2001},
  month = sep,
  publisher = {Elsevier {BV}},
  volume = {471},
  number = {1-2},
  pages = {98--102},
  author = {Mikael Persson and Dianna Bone and H{\aa}kan Elmqvist},
  title = {Three-dimensional total variation norm for {SPECT} reconstruction},
  journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators,  Spectrometers,  Detectors and Associated Equipment}
}

 @inproceedings{Bergner,
  doi = {10.1109/nssmic.2005.1596967},
  url = {https://doi.org/10.1109/nssmic.2005.1596967},
  publisher = {{IEEE}},
  author = {S. Bergner and E. Dagenais and A. Celler and T. Moeller},
  title = {Using the Physics-based Rendering Toolkit for Medical Reconstruction},
  booktitle = {{IEEE} Nuclear Science Symposium Conference Record,  2005}
}

% monte carlo spect
@article{Beck1982,
  doi = {10.1109/tns.1982.4335896},
  url = {https://doi.org/10.1109/tns.1982.4335896},
  year = {1982},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {29},
  number = {1},
  pages = {506--511},
  author = {John W. Beck and Ronald J. Jaszczak and R. Edward Coleman and C. Frank Starmer and Loren W. Nolte},
  title = {Analysis of {SPECT} including Scatter and Attenuation Using Sophisticated Monte Carlo Modeling Methods},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Floyd1984,
  doi = {10.1088/0031-9155/29/10/005},
  url = {https://doi.org/10.1088/0031-9155/29/10/005},
  year = {1984},
  month = oct,
  publisher = {{IOP} Publishing},
  volume = {29},
  number = {10},
  pages = {1217--1230},
  author = {C E Floyd and R J Jaszczak and C C Harris and R E Coleman},
  title = {Energy and spatial distribution of multiple order Compton scatter in {SPECT}: a Monte Carlo investigation},
  journal = {Physics in Medicine and Biology}
}

@article{Ljungberg1989,
  doi = {10.1016/0169-2607(89)90111-9},
  url = {https://doi.org/10.1016/0169-2607(89)90111-9},
  year = {1989},
  month = aug,
  publisher = {Elsevier {BV}},
  volume = {29},
  number = {4},
  pages = {257--272},
  author = {Michael Ljungberg and Sven-Erik Strand},
  title = {A Monte Carlo program for the simulation of scintillation camera characteristics},
  journal = {Computer Methods and Programs in Biomedicine}
}

@Article{pmid2045947,
   Author="Ljungberg, M.  and Strand, S. E.",
   Title="{Attenuation and scatter correction in SPECT for sources in a nonhomogeneous object: a Monte Carlo study}",
   Journal="J. Nucl. Med.",
   Year="1991",
   Volume="32",
   Number="6",
   Pages="1278--1284",
   Month="Jun"
}

@article{Haynor1991,
  doi = {10.1118/1.596615},
  url = {https://doi.org/10.1118/1.596615},
  year = {1991},
  month = sep,
  publisher = {Wiley},
  volume = {18},
  number = {5},
  pages = {990--1001},
  author = {David R. Haynor and Robert L. Harrison and Thomas K. Lewellen},
  title = {The use of importance sampling techniques to improve the efficiency of photon tracking in emission tomography simulations},
  journal = {Medical Physics}
}

@Book{ljungberg1998monte,
 author = {Ljungberg, Michael},
 title = {Monte Carlo calculations in nuclear medicine : applications in diagnostic imaging},
 publisher = {Institute of Physics Pub},
 year = {1998},
 address = {Bristol Philadelphia},
 isbn = {9780750304795}
 }

@article{Song2005,
  doi = {10.1088/0031-9155/50/8/011},
  url = {https://doi.org/10.1088/0031-9155/50/8/011},
  year = {2005},
  month = apr,
  publisher = {{IOP} Publishing},
  volume = {50},
  number = {8},
  pages = {1791--1804},
  author = {X Song and W P Segars and Y Du and B M W Tsui and E C Frey},
  title = {Fast modelling of the collimator{\textendash}detector response in Monte Carlo simulation of {SPECT} imaging using the angular response function},
  journal = {Physics in Medicine and Biology}
}

% scatter correction
@article{Beekman1999,
  doi = {10.1088/0031-9155/44/8/402},
  url = {https://doi.org/10.1088/0031-9155/44/8/402},
  year = {1999},
  month = jul,
  publisher = {{IOP} Publishing},
  volume = {44},
  number = {8},
  pages = {N183--N192},
  author = {Freek J Beekman and Hugo W A M de Jong and Eddy T P Slijpen},
  title = {Efficient {SPECT} scatter calculation in non-uniform media using correlated Monte Carlo simulation},
  journal = {Physics in Medicine and Biology}
}

@article{Jong2001,
  doi = {10.1088/0031-9155/46/3/301},
  url = {https://doi.org/10.1088/0031-9155/46/3/301},
  year = {2001},
  month = jan,
  publisher = {{IOP} Publishing},
  volume = {46},
  number = {3},
  pages = {621--635},
  author = {Hugo W A M de Jong and Freek J Beekman},
  title = {Rapid {SPECT} simulation of downscatter in non-uniform media},
  journal = {Physics in Medicine and Biology}
}

@article{deJong2001,
  doi = {10.1109/23.910833},
  url = {https://doi.org/10.1109/23.910833},
  year = {2001},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {48},
  number = {1},
  pages = {58--64},
  author = {H.W.A.M. de Jong and E.T.P. Slijpen and F.J. Beekman},
  title = {Acceleration of Monte Carlo {SPECT} simulation using convolution-based forced detection},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Beekman2002,
  doi = {10.1109/tmi.2002.803130},
  url = {https://doi.org/10.1109/tmi.2002.803130},
  year = {2002},
  month = aug,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {21},
  number = {8},
  pages = {867--877},
  author = {F.J. Beekman and H.W.A.M. de Jong and S. van Geloven},
  title = {Efficient fully 3-D iterative {SPECT} reconstruction with Monte Carlo-based scatter compensation},
  journal = {{IEEE} Transactions on Medical Imaging}
}

@article{deWit2005,
  doi = {10.1109/tns.2005.858220},
  url = {https://doi.org/10.1109/tns.2005.858220},
  year = {2005},
  month = oct,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {52},
  number = {5},
  pages = {1365--1369},
  author = {T.C. de Wit and  Jianbin Xiao and F.J. Beekman},
  title = {Monte Carlo-based statistical {SPECT} reconstruction: influence of number of photon tracks},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Sohlberg2008,
  doi = {10.1088/0031-9155/53/14/n02},
  url = {https://doi.org/10.1088/0031-9155/53/14/n02},
  year = {2008},
  month = jun,
  publisher = {{IOP} Publishing},
  volume = {53},
  number = {14},
  pages = {N277--N285},
  author = {A Sohlberg and H Watabe and H Iida},
  title = {Acceleration of Monte Carlo-based scatter compensation for cardiac {SPECT}},
  journal = {Physics in Medicine and Biology}
}

@article{Hutton2011,
  doi = {10.1088/0031-9155/56/14/r01},
  url = {https://doi.org/10.1088/0031-9155/56/14/r01},
  year = {2011},
  month = jun,
  publisher = {{IOP} Publishing},
  volume = {56},
  number = {14},
  pages = {R85--R112},
  author = {Brian F Hutton and Ir{\`{e}}ne Buvat and Freek J Beekman},
  title = {Review and current status of {SPECT} scatter correction},
  journal = {Physics in Medicine and Biology}
}

% attenuation correction
@article{LaCroix1994,
  doi = {10.1109/23.340649},
  url = {https://doi.org/10.1109/23.340649},
  year = {1994},
  month = dec,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {41},
  number = {6},
  pages = {2793--2799},
  author = {K.J. LaCroix and B.M.W. Tsui and B.H. Hasegawa and J.K. Brown},
  title = {Investigation of the use of X-ray {CT} images for attenuation compensation in {SPECT}},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Patton2008,
  doi = {10.2967/jnmt.107.046839},
  url = {https://doi.org/10.2967/jnmt.107.046839},
  year = {2008},
  month = mar,
  publisher = {Society of Nuclear Medicine},
  volume = {36},
  number = {1},
  pages = {1--10},
  author = {J. A. Patton and T. G. Turkington},
  title = {{SPECT}/{CT} Physical Principles and Attenuation Correction},
  journal = {Journal of Nuclear Medicine Technology}
}

% CT to LAC
@inproceedings{inproceedings,
author = {Crawley, Edward and Evans, William and Owen, Glynn},
year = {1985},
month = {01},
pages = {93},
title = {Abstract: The measurement of effective energy and linear attenuation coefficient in a x-ray CT scanner},
volume = {30},
journal = {Physics in Medicine and Biology}
}

@article{Watanabe1999,
  doi = {10.1088/0031-9155/44/9/308},
  url = {https://doi.org/10.1088/0031-9155/44/9/308},
  year = {1999},
  month = aug,
  publisher = {{IOP} Publishing},
  volume = {44},
  number = {9},
  pages = {2201--2211},
  author = {Yoichi Watanabe},
  title = {Derivation of linear attenuation coefficients from {CT} numbers for low-energy photons},
  journal = {Physics in Medicine and Biology}
}

@article{ChuanyongBai2003,
  doi = {10.1109/tns.2003.817281},
  url = {https://doi.org/10.1109/tns.2003.817281},
  year = {2003},
  month = oct,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {50},
  number = {5},
  pages = {1510--1515},
  author = {Chuanyong Bai and  Ling Shao and A.J. Da Silva and  Zuo Zhao},
  title = {A generalized model for the conversion from ct numbers to linear attenuation coefficients},
  journal = {{IEEE} Transactions on Nuclear Science}
}

% databases
@article{White1987,
  doi = {10.1259/0007-1285-60-717-907},
  url = {https://doi.org/10.1259/0007-1285-60-717-907},
  year = {1987},
  month = sep,
  publisher = {British Institute of Radiology},
  volume = {60},
  number = {717},
  pages = {907--913},
  author = {D. R. White and H. Q. Woodard and S. M. Hammond},
  title = {Average soft-tissue and bone models for use in radiation dosimetry},
  journal = {The British Journal of Radiology}
}

@article{White1989,
  doi = {10.1093/jicru/os23.1.report44},
  url = {https://doi.org/10.1093/jicru/os23.1.report44},
  year = {1989},
  month = jan,
  publisher = {{SAGE} Publications},
  volume = {os23},
  number = {1},
  pages = {NP--NP},
  author = {D. R. White and J. Booz and R. V. Griffith and J. J. Spokas and I. J. Wilson},
  title = {Report 44},
  journal = {Journal of the International Commission on Radiation Units and Measurements}
}

@misc{xcom,
  doi = {10.18434/T48G6X},
  url = {http://www.nist.gov/pml/data/xcom/index.cfm},
  author = {Seltzer,  Stephen},
  language = {eng},
  title = {XCOM-Photon Cross Sections Database,  NIST Standard Reference Database 8},
  publisher = {National Institute of Standards and Technology},
  year = {1987}
}

%%%%%%%%%%%%%%%%
@inproceedings{Ronneberger2015,
abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-24574-4_28},
issn = {16113349},
title = {{U-net: Convolutional networks for biomedical image segmentation}},
volume = {9351},
year = {2015}
}

@article{Shapiro2001,
abstract = {A c hanging scene may be observed via a sequence of images. One might learn a golf swing by observing the motions of an expert with a video camera, or better understand root growth by observing the root using many images taken hours apart. Action phenomena observed over time can be due to the motion of objects or the observer or both. Changes in an im-age sequence provide features for detecting objects that are moving or for computing their trajectories. In case the viewer is moving through a relatively static world, image changes allow for computing the motion of the viewer in the world. Similarly changing pixels in an image provide an important feature for object detection and recognition. Motion can reveal the shape of an object as well as other characteristics, such as speed or function. Analysis of object motion over time may be the ultimate goal, for instance in controlling trac ow or in analyzing the gait of a person with a new prosthesis. Today, a h uge amount of videos are made to record events and structure of the world. It is necessary to have methods of segmenting these image sequences into meaningful events or scenes for easy access, analysis or editing. This chapter concentrates on detection of motion from 2D images and video sequences and the image analysis used to extract features. Methods for solution of the above applicaton problems are discussed. Analysis of 3D structure and motion derived from 2D images is discussed in Chapter 13.},
author = {Shapiro, Linda G. and Stockman, George C.},
isbn = {0-13-030796-3},
journal = {Computer Vision},
title = {{Motion from 2D Image Sequences}},
year = {2001}
}

@article{Kim2020,
abstract = {Recent state-of-the-art image segmentation algorithms are mostly based on deep neural networks, thanks to their high performance and fast computation time. However, these methods are usually trained in a supervised manner, which requires large number of high quality ground-truth segmentation masks. On the other hand, classical image segmentation approaches such as level-set methods are formulated in a self-supervised manner by minimizing energy functions such as Mumford-Shah functional, so they are still useful to help generate segmentation masks without labels. Unfortunately, these algorithms are usually computationally expensive and often have limitation in semantic segmentation. In this paper, we propose a novel loss function based on Mumford-Shah functional that can be used in deep-learning based image segmentation without or with small labeled data. This loss function is based on the observation that the softmax layer of deep neural networks has striking similarity to the characteristic function in the Mumford-Shah functional. We show that the new loss function enables semi-supervised and unsupervised segmentation. In addition, our loss function can also be used as a regularized function to enhance supervised semantic segmentation algorithms. Experimental results on multiple datasets demonstrate the effectiveness of the proposed method.},
archivePrefix = {arXiv},
arxivId = {1904.02872},
author = {Kim, Boah and Ye, Jong Chul},
doi = {10.1109/TIP.2019.2941265},
eprint = {1904.02872},
issn = {19410042},
journal = {IEEE Transactions on Image Processing},
keywords = {Mumford-Shah functional,Semi-supervised learning,image segmentation,unsupervised learning},
title = {{Mumford-shah loss functional for image segmentation with deep learning}},
year = {2020}
}

@article{Buda1992,
abstract = {Chirality is a property that is independent of its physical and chemical manifestations. It is therefore possible to quantify chirality without any reference to pseudoscalar observables. In this paper we propose a new measure of chirality that is based on Hausdorff s concept of distances between sets and that is a natural choice as a measure for molecular models that represent structures as sets of atomic coordinates. This Hausdorff chirality measure, a continuous and similarity-invariant function of an object's shape, is zero if and only if the object is achiral. We have applied this measure to study the chirality of tetrahedral shapes—classical models of tetracoordinate carbon atoms—and have identified the extremal (most chiral) shapes for every chiral subsymmetry of Td that can be realized by a tetrahedron. Our calculations show that the degree of chirality of the extremal objects increases with a decrease in symmetry, although the most symmetric chiral tetrahedron, with D2 symmetry, already possesses 87{\%} of the maximal chirality value available for tetrahedra, and that the shape of the most chiral tetrahedron, with C1 symmetry, is very close to that of the most chiral C2 tetrahedron. The properties and the applicability of the Hausdorff chirality measure are compared with those of other measures of chirality that are based on common-volume or root-mean-square approaches. {\textcopyright} 1992, American Chemical Society. All rights reserved.},
author = {Buda, Andrzej B. and Mislow, Kurt},
doi = {10.1021/ja00041a016},
issn = {15205126},
journal = {Journal of the American Chemical Society},
title = {{A Hausdorff Chirality Measure}},
year = {1992}
}

@article{Wu1982,
abstract = {This is a tutorial review on the Potts model aimed at bringing out in an organized fashion the essential and important properties of the standard Potts model. Emphasis is placed on exact and rigorous results, but other aspects of the problem are also described to achieve a unified perspective. Topics reviewed include the mean-field theory, duality relations, series expansions, critical properties, experimental realizations, and the relationship of the Potts model with other lattice-statistical problems. {\textcopyright} 1982 American Physical Society.},
author = {Wu, F. Y.},
doi = {10.1103/RevModPhys.54.235},
issn = {00346861},
journal = {Reviews of Modern Physics},
title = {{The Potts model}},
year = {1982}
}

@inproceedings{Zhang2018,
abstract = {Deep neural networks (DNNs) have achieved tremendous success in a variety of applications across many disciplines. Yet, their superior performance comes with the expensive cost of requiring correctly annotated large-scale datasets. Moreover, due to DNNs' rich capacity, errors in training labels can hamper performance. To combat this problem, mean absolute error (MAE) has recently been proposed as a noise-robust alternative to the commonly-used categorical cross entropy (CCE) loss. However, as we show in this paper, MAE can perform poorly with DNNs and challenging datasets. Here, we present a theoretically grounded set of noise-robust loss functions that can be seen as a generalization of MAE and CCE. Proposed loss functions can be readily applied with any existing DNN architecture and algorithm, while yielding good performance in a wide range of noisy label scenarios. We report results from experiments conducted with CIFAR-10, CIFAR-100 and FASHION-MNIST datasets and synthetically generated noisy labels.},
archivePrefix = {arXiv},
arxivId = {1805.07836},
author = {Zhang, Zhilu and Sabuncu, Mert R.},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1805.07836},
issn = {10495258},
title = {{Generalized cross entropy loss for training deep neural networks with noisy labels}},
year = {2018}
}

@article{Thada2013,
abstract = {A similarity coefficient represents the similarity between two documents, two queries, or one document and one query. The retrieved documents can also be ranked in the order of presumed importance. A similarity coefficient is a function which computes the degree of similarity between a pair of text objects. There are a large number of similarity coefficients proposed in the literature, because the best similarity measure doesn't exist (yet !). In this paper we do a comparative analysis for finding out the most relevant document for the given set of keyword by using three similarity coefficients viz Jaccard, Dice and Cosine coefficients. This we perform using genetic algorithm approach. Due to the randomized nature of genetic algorithm the best fitness value is the average of 10 runs of the same code for a fixed number of iterations.The similarity coefficient for a set of documents retrieved for a given query from Google are find out then average relevancy in terms of fitness values using similarity coefficients is calculated. In this paper we have averaged 10 different generations for each query by running the program 10 times for the fixed value of Probability of Crossover Pc=0.7 and Probability of Mutation Pm=0.01. The same experiment was conducted for 10 queries.},
author = {Thada, Vikas and Jaglan, Vivek},
journal = {International Journal of Innovations in Engineering and Technology},
title = {{Comparison of jaccard, dice, cosine similarity coefficient to find best fitness value for web retrieved documents using genetic algorithm}},
year = {2013}
}


@article{Liao2018,
abstract = {Automatic vertebrae identification and localization from arbitrary computed tomography (CT) images is challenging. Vertebrae usually share similar morphological appearance. Because of pathology and the arbitrary field-of-view of CT scans, one can hardly rely on the existence of some anchor vertebrae or parametric methods to model the appearance and shape. To solve the problem, we argue that: 1) one should make use of the short-range contextual information, such as the presence of some nearby organs (if any), to roughly estimate the target vertebrae; and 2) due to the unique anatomic structure of the spine column, vertebrae have fixed sequential order, which provides the important long-range contextual information to further calibrate the results. We propose a robust and efficient vertebrae identification and localization system that can inherently learn to incorporate both the short- and long-range contextual information in a supervised manner. To this end, we develop a multi-task 3-D fully convolutional neural network to effectively extract the short-range contextual information around the target vertebrae. For the long-range contextual information, we propose a multi-task bidirectional recurrent neural network to encode the spatial and contextual information among the vertebrae of the visible spine column. We demonstrate the effectiveness of the proposed approach on a challenging data set, and the experimental results show that our approach outperforms the state-of-the-art methods by a significant margin.},
archivePrefix = {arXiv},
arxivId = {1812.03500},
author = {Liao, Haofu and Mesfin, Addisu and Luo, Jiebo},
doi = {10.1109/TMI.2018.2798293},
eprint = {1812.03500},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Automatic vertebrae identification and localization,CT image,convolutional neural network,deep learning,multi-task learning,recurrent neural network},
pmid = {29727289},
title = {{Joint vertebrae identification and localization in spinal CT images by combining short- and long-range contextual information}},
year = {2018}
}


@article{Barker1996,
abstract = {This article discusses the use of the four main types of medical imaging, i.e. x-ray, radionuclide, ultrasound and magnetic resonance, and considers their relative merits. Important recent and possible future developments in image processing are also described. {\textcopyright} 1996.},
author = {Barker, M. C.J.},
doi = {10.1088/0031-9120/31/2/013},
issn = {13616552},
journal = {Physics Education},
title = {{Medical imaging}},
year = {1996}
}


@article{Ahlberg2005,
abstract = {Ichthyostega was the first Devonian tetrapod to be subject to a whole-body reconstruction. It remains, together with Acanthostega, one of only two Devonian tetrapods for which near-complete postcranial material is available. It is thus crucially important for our understanding of the earliest stages of tetrapod evolution and terrestrialization. Here we show a new reconstruction of Ichthyostega based on extensive re-examination of original material and augmented by recently collected specimens. Our reconstruction differs substantially from those previously published and reveals hitherto unrecognized regionalization in the vertebral column. Ichthyostega is the earliest vertebrate to show obvious adaptations for non-swimming locomotion. Uniquely among early tetrapods, the presacral vertebral column shows pronounced regionalization of neural arch morphology, suggesting that it was adapted for dorsoventral rather than lateral flexion. {\textcopyright} 2005 Nature Publishing Group.},
author = {Ahlberg, Per Erik and Clack, Jennifer A. and Blom, Henning},
doi = {10.1038/nature03893},
issn = {14764687},
journal = {Nature},
pmid = {16136143},
title = {{The axial skeleton of the Devonian tetrapod Ichthyostega}},
year = {2005}
}

@article{Pham2000,
abstract = {Image segmentation plays a crucial role in many medical-imaging applications, by automating or facilitating the delineation of anatomical structures and other regions of interest. We present a critical appraisal of the current status of semi-automated and automated methods for the segmentation of anatomical medical images. Terminology and important issues in image segmentation are first presented. Current segmentation approaches are then reviewed with an emphasis on the advantages and disadvantages of these methods for medical imaging applications. We conclude with a discussion on the future of image segmentation methods in biomedical research.},
author = {Pham, Dzung L. and Xu, Chenyang and Prince, Jerry L.},
doi = {10.1146/annurev.bioeng.2.1.315},
issn = {15239829},
journal = {Annual Review of Biomedical Engineering},
keywords = {Classification,Deformable models,Image processing,Magnetic resonance imaging,Medical imaging},
pmid = {11701515},
title = {{Current methods in medical image segmentation}},
year = {2000}
}

@inproceedings{Ronneberger2015,
abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
archivePrefix = {arXiv},
arxivId = {1505.04597},
author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-24574-4_28},
eprint = {1505.04597},
isbn = {9783319245737},
issn = {16113349},
title = {{U-net: Convolutional networks for biomedical image segmentation}},
year = {2015}
}

@article{Seeram2004,
abstract = {Digital image processing is now commonplace in radiology, nuclear medicine and sonography. This article outlines underlying principles and concepts of digital image processing. After completing this article, readers should be able to: List the limitations of film-based imaging. Identify major components of a digital imaging system. Describe the history and application areas of digital image processing. Discuss image representation and the fundamentals of digital image processing. Outline digital image processing techniques and processing operations used in selected imaging modalities. Explain the basic concepts and visualization tools used in 3-D and virtual reality imaging. Recognize medical imaging informatics as a new area of specialization for radiologic technologists.},
author = {Seeram, Euclid},
doi = {10.4324/9781315693125-12},
issn = {00338397},
journal = {Radiologic technology},
pmid = {15352557},
title = {{Digital image processing.}},
year = {2004}
}

@article{Duncan2000,
abstract = {The analysis of medical images has been woven into the fabric of the Pattern Analysis and Machine Intelligence (PAMI) community since the earliest days of these Transactions. Initially, the efforts in this area were seen as applying pattern analysis and computer vision techniques to another interesting dataset. However, over the last two to three decades, the unique nature of the problems presented within this area of study have led to the development of a new discipline in its own right. Examples of these include: the types of image information that are acquired, the fully three-dimensional image data, the nonrigid nature of object motion and deformation, and the statistical variation of both the underlying normal and abnormal ground truth. In this paper, we look at progress in the field over the last 20 years and suggest some of the challenges that remain for the years to come.},
author = {Duncan, James S. and Ayache, Nicholas},
doi = {10.1109/34.824822},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
title = {{Medical image analysis: Progress over two decades and the challenges ahead}},
year = {2000}
}


@article{Wang2020,
abstract = {Thyroid nodules have a high prevalence and a small percentage is malignant. Many non-invasive methods have been developed with the help of the Internet of Things to improve the detection rate of malignant nodules. These methods can be roughly categorized into two classes: radiomics based and deep learning based approaches. In general, convolutional neural networks based deep learning methods have achieved promising performance in many medical image analysis and classification applications; however, no existing comparison has been done between radiomics based and deep learning based approaches. Therefore, in this paper, we aim to compare the performance of radiomics and deep learning based methods for the classification of thyroid nodules from ultrasound images. On one hand, we developed a radiomics based method, which consists of extracting high throughput 302-dimensional statistical features from pre-processed images. Then dimension reduction was performed using mutual information and linear discriminant analysis respectively to achieve the final classification. On the other hand, a deep learning based method was also developed and tested by pre-training a VGG16 model with fine-tuning. Ultrasound images including 3120 images (1841 benign nodules and 1393 malignant nodules) from 1040 cases were retrospectively collected. The dataset was divided into 80{\%} training and 20{\%} testing data. The highest accuracies yielded on the testing data for radiomics and deep learning based methods were 66.81{\%} and 74.69{\%}, respectively. A comparison result demonstrated that the deep learning based method can achieve a better performance than using radiomics.},
author = {Wang, Yongfeng and Yue, Wenwen and Li, Xiaolong and Liu, Shuyu and Guo, Lehang and Xu, Huixiong and Zhang, Heye and Yang, Guang},
doi = {10.1109/ACCESS.2020.2980290},
issn = {21693536},
journal = {IEEE Access},
keywords = {Ultrasound images,convolutional neural network,nodule classification,radiomics,thyroid cancer,thyroid nodule},
title = {{Comparison Study of Radiomics and Deep Learning-Based Methods for Thyroid Nodules Classification Using Ultrasound Images}},
year = {2020}
}


@misc{Anwar2018,
abstract = {The science of solving clinical problems by analyzing images generated in clinical practice is known as medical image analysis. The aim is to extract information in an affective and efficient manner for improved clinical diagnosis. The recent advances in the field of biomedical engineering have made medical image analysis one of the top research and development area. One of the reasons for this advancement is the application of machine learning techniques for the analysis of medical images. Deep learning is successfully used as a tool for machine learning, where a neural network is capable of automatically learning features. This is in contrast to those methods where traditionally hand crafted features are used. The selection and calculation of these features is a challenging task. Among deep learning techniques, deep convolutional networks are actively used for the purpose of medical image analysis. This includes application areas such as segmentation, abnormality detection, disease classification, computer aided diagnosis and retrieval. In this study, a comprehensive review of the current state-of-the-art in medical image analysis using deep convolutional networks is presented. The challenges and potential of these techniques are also highlighted.},
archivePrefix = {arXiv},
arxivId = {1709.02250},
author = {Anwar, Syed Muhammad and Majid, Muhammad and Qayyum, Adnan and Awais, Muhammad and Alnowami, Majdi and Khan, Muhammad Khurram},
booktitle = {Journal of Medical Systems},
doi = {10.1007/s10916-018-1088-1},
eprint = {1709.02250},
issn = {1573689X},
keywords = {Classification,Computer aided diagnosis,Convolutional neural network,Medical image analysis,Segmentation},
pmid = {30298337},
title = {{Medical Image Analysis using Convolutional Neural Networks: A Review}},
year = {2018}
}


@inproceedings{Suzani2015,
abstract = {{\textcopyright} 2015 SPIE. This paper proposes an automatic method for vertebra localization, labeling, and segmentation in multi-slice Magnetic Resonance (MR) images. Prior work in this area on MR images mostly requires user interaction while our method is fully automatic. Cubic intensity-based features are extracted from image voxels. A deep learning approach is used for simultaneous localization and identification of vertebrae. The localized points are refined by local thresholding in the region of the detected vertebral column. Thereafter, a statistical multi-vertebrae model is initialized on the localized vertebrae. An iterative Expectation Maximization technique is used to register the vertebral body of the model to the image edges and obtain a segmentation of the lumbar vertebral bodies. The method is evaluated by applying to nine volumetric MR images of the spine. The results demonstrate 100{\%} vertebra identification and a mean surface error of below 2.8 mm for 3D segmentation. Computation time is less than three minutes per high-resolution volumetric image.},
author = {Suzani, Amin and Rasoulian, Abtin and Seitel, Alexander and Fels, Sidney and Rohling, Robert N. and Abolmaesumi, Purang},
booktitle = {Medical Imaging 2015: Image-Guided Procedures, Robotic Interventions, and Modeling},
doi = {10.1117/12.2081542},
isbn = {9781628415056},
issn = {1605-7422},
title = {{Deep learning for automatic localization, identification, and segmentation of vertebral bodies in volumetric MR images}},
year = {2015}
}

@inproceedings{Hosseini2017,
abstract = {Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance on a variety of computer vision tasks, particularly visual classification problems, where new algorithms reported to achieve or even surpass the human performance. In this paper, we examine whether CNNs are capable of learning the semantics of training data. To this end, we evaluate CNNs on negative images, since they share the same structure and semantics as regular images and humans can classify them correctly. Our experimental results indicate that when training on regular images and testing on negative images, the model accuracy is significantly lower than when it is tested on regular images. This leads us to the conjecture that current training methods do not effectively train models to generalize the concepts. We then introduce the notion of semantic adversarial examples-transformed inputs that semantically represent the same objects, but the model does not classify them correctly- A nd present negative images as one class of such inputs.},
archivePrefix = {arXiv},
arxivId = {1703.06857},
author = {Hosseini, Hossein and Xiao, Baicen and Jaiswal, Mayoore and Poovendran, Radha},
booktitle = {Proceedings - 16th IEEE International Conference on Machine Learning and Applications, ICMLA 2017},
doi = {10.1109/ICMLA.2017.0-136},
eprint = {1703.06857},
isbn = {9781538614174},
keywords = {Convolutional Neural Networks,Negative Images},
title = {{On the limitation of convolutional neural networks in recognizing negative images}},
year = {2017}
}


@article{Jing2020,
abstract = {The seminal work of Gatys et al. demonstrated the power of Convolutional Neural Networks (CNNs) in creating artistic imagery by separating and recombining image content and style. This process of using CNNs to render a content image in different styles is referred to as Neural Style Transfer (NST). Since then, NST has become a trending topic both in academic literature and industrial applications. It is receiving increasing attention and a variety of approaches are proposed to either improve or extend the original NST algorithm. In this paper, we aim to provide a comprehensive overview of the current progress towards NST. We first propose a taxonomy of current algorithms in the field of NST. Then, we present several evaluation methods and compare different NST algorithms both qualitatively and quantitatively. The review concludes with a discussion of various applications of NST and open problems for future research. A list of papers discussed in this review, corresponding codes, pre-trained models and more comparison results are publicly available at: https://osf.io/f8tu4/.},
archivePrefix = {arXiv},
arxivId = {1705.04058},
author = {Jing, Yongcheng and Yang, Yezhou and Feng, Zunlei and Ye, Jingwen and Yu, Yizhou and Song, Mingli},
doi = {10.1109/TVCG.2019.2921336},
eprint = {1705.04058},
issn = {19410506},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Neural style transfer (NST),convolutional neural network (CNN)},
pmid = {31180860},
title = {{Neural Style Transfer: A Review}},
year = {2020}
}


@article{Zou2020,
abstract = {We study the problem of training deep fully connected neural networks with Rectified Linear Unit (ReLU) activation function and cross entropy loss function for binary classification using gradient descent. We show that with proper random weight initialization, gradient descent can find the global minima of the training loss for an over-parameterized deep ReLU network, under certain assumption on the training data. The key idea of our proof is that Gaussian random initialization followed by gradient descent produces a sequence of iterates that stay inside a small perturbation region centered at the initial weights, in which the training loss function of the deep ReLU networks enjoys nice local curvature properties that ensure the global convergence of gradient descent. At the core of our proof technique is (1) a milder assumption on the training data; (2) a sharp analysis of the trajectory length for gradient descent; and (3) a finer characterization of the size of the perturbation region. Compared with the concurrent work (Allen-Zhu et al. in A convergence theory for deep learning via over-parameterization, 2018a; Du et al. in Gradient descent finds global minima of deep neural networks, 2018a) along this line, our result relies on milder over-parameterization condition on the neural network width, and enjoys faster global convergence rate of gradient descent for training deep neural networks.},
author = {Zou, Difan and Cao, Yuan and Zhou, Dongruo and Gu, Quanquan},
doi = {10.1007/s10994-019-05839-6},
issn = {15730565},
journal = {Machine Learning},
keywords = {Deep neural networks,Global convergence,Gradient descent,Over-parameterization,Random initialization},
title = {{Gradient descent optimizes over-parameterized deep ReLU networks}},
year = {2020}
}


@misc{Boudiaf2020,
abstract = {Copyright {\textcopyright} 2020, arXiv, All rights reserved. Recently, substantial research efforts in Deep Metric Learning (DML) focused on designing complex pairwise-distance losses and convoluted sample-mining and implementation strategies to ease optimization. The standard cross-entropy loss for classification has been largely overlooked in DML. On the surface, the cross-entropy may seem unrelated and irrelevant to metric learning as it does not explicitly involve pairwise distances. However, we provide a theoretical analysis that links the cross-entropy to several well-known and recent pairwise losses. Our connections are drawn from two different perspectives: one based on an explicit optimization insight; the other on discriminative and generative views of the mutual information between the labels and the learned features. First, we explicitly demonstrate that the cross-entropy is an upper bound on a new pairwise loss, which has a structure similar to various pairwise losses: it minimizes intra-class distances while maximizing inter-class distances. As a result, minimizing the cross-entropy can be seen as an approximate bound-optimization (or Majorize-Minimize) algorithm for minimizing this pairwise loss. Second, we show that, more generally, minimizing the cross-entropy is actually equivalent to maximizing the mutual information, to which we connect several well-known pairwise losses. These findings indicate that the cross-entropy represents a proxy for maximizing the mutual information - as pairwise losses do - without the need for complex sample-mining and optimization schemes. Furthermore, we show that various standard pairwise losses can be explicitly related to one another via bound relationships. Our experiments† over four standard DML benchmarks (CUB200, Cars-196, Stanford Online Product and In-Shop) strongly support our findings. We consistently obtained state-of-the-art results, outperforming many recent and complex DML methods.},
author = {Boudiaf, M. and Rony, J. and Ziko, I.M. and Granger, E. and Pedersoli, M. and Piantanida, P. and Ayed, I.B.},
booktitle = {arXiv},
keywords = {Deep Learning,Information Theory,Metric Learning},
title = {{Metric learning: Cross-entropy vs. pairwise losses}},
year = {2020}
}


@article{Chen2019,
abstract = {Online semi-supervised learning (OS2L) has received much attention recently because of its well practical usefulness. Most of the existing studies of OS2L are related to manifold regularization. In this paper, we introduce a novel OS2L framework with multiple regularization terms based on the notion of ascending the dual function in constrained optimization. Using the Fenchel conjugate, different semi-supervised regularization terms can be integrated into the dual function easily and directly. This approach is derived by updating limited dual coefficient variables on each learning round. To be practical, we also employ buffering strategies and sparse approximation approaches in this paper. The experimental studies show that our methods achieve accuracy comparable to offline algorithms while consuming less time and memory. Especially, our OS2L algorithms can handle the settings where the target hyperplane of classification continually drifts with the sequence of arriving instances. This paper paves a way to design and analyze OS2L algorithms with multiple regularization terms.},
author = {Chen, Chao and Sun, Boliang and Hu, Xingchen and Li, Yan},
doi = {10.1109/ACCESS.2019.2897382},
issn = {21693536},
journal = {IEEE Access},
keywords = {Fenchel conjugate,Online semi-supervised learning (OS2L),SVM,co-regularization,manifold regularization},
title = {{Online Semi-Supervised Learning With Multiple Regularization Terms}},
year = {2019}
}


@article{Janocha2016,
abstract = {Deep neural networks are currently among the most commonly used classifiers. Despite easily achieving very good performance, one of the best selling points of these models is their modular design - one can conveniently adapt their architecture to specific needs, change connectivity patterns, attach specialised layers, experiment with a large amount of activation functions, normalisation schemes and many others. While one can find impressively wide spread of various configurations of almost every aspect of the deep nets, one element is, in authors' opinion, underrepresented - while solving classification problems, vast majority of papers and applications simply use log loss. In this paper we try to investigate how particular choices of loss functions affect deep models and their learning dynamics, as well as resulting classifiers robustness to various effects. We perform experiments on classical datasets, as well as provide some additional, theoretical insights into the problem. In particular we show that L1 and L2 losses are, quite surprisingly, justified classification objectives for deep nets, by providing probabilistic interpretation in terms of expected misclassification. We also introduce two losses which are not typically used as deep nets objectives and show that they are viable alternatives to the existing ones.},
archivePrefix = {arXiv},
arxivId = {1702.05659},
author = {Janocha, Katarzyna and Czarnecki, Wojciech Marian},
doi = {10.4467/20838476SI.16.004.6185},
eprint = {1702.05659},
issn = {20838476},
journal = {Schedae Informaticae},
keywords = {Classification theory.,Deep learning,Loss function},
title = {{On loss functions for deep neural networks in classification}},
year = {2016}
}


@article{Eckle2019,
abstract = {Deep neural networks (DNNs) generate much richer function spaces than shallow networks. Since the function spaces induced by shallow networks have several approximation theoretic drawbacks, this explains, however, not necessarily the success of deep networks. In this article we take another route by comparing the expressive power of DNNs with ReLU activation function to linear spline methods. We show that MARS (multivariate adaptive regression splines) is improper learnable by DNNs in the sense that for any given function that can be expressed as a function in MARS with M parameters there exists a multilayer neural network with O(Mlog(M∕$\epsilon$)) parameters that approximates this function up to sup-norm error $\epsilon$. We show a similar result for expansions with respect to the Faber–Schauder system. Based on this, we derive risk comparison inequalities that bound the statistical risk of fitting a neural network by the statistical risk of spline-based methods. This shows that deep networks perform better or only slightly worse than the considered spline methods. We provide a constructive proof for the function approximations.},
archivePrefix = {arXiv},
arxivId = {1804.02253},
author = {Eckle, Konstantin and Schmidt-Hieber, Johannes},
doi = {10.1016/j.neunet.2018.11.005},
eprint = {1804.02253},
issn = {18792782},
journal = {Neural Networks},
keywords = {Deep neural networks,Faber–Schauder system,MARS,Nonparametric regression,Rates of convergence,Splines},
pmid = {30616095},
title = {{A comparison of deep networks with ReLU activation function and linear spline-type methods}},
year = {2019}
}


@misc{Apicella2021,
abstract = {In neural networks literature, there is a strong interest in identifying and defining activation functions which can improve neural network performance. In recent years there has been a renovated interest in the scientific community in investigating activation functions which can be trained during the learning process, usually referred to as trainable, learnable or adaptable activation functions. They appear to lead to better network performance. Diverse and heterogeneous models of trainable activation function have been proposed in the literature. In this paper, we present a survey of these models. Starting from a discussion on the use of the term “activation function” in literature, we propose a taxonomy of trainable activation functions, highlight common and distinctive proprieties of recent and past models, and discuss main advantages and limitations of this type of approach. We show that many of the proposed approaches are equivalent to adding neuron layers which use fixed (non-trainable) activation functions and some simple local rule that constrains the corresponding weight layers.},
archivePrefix = {arXiv},
arxivId = {2005.00817},
author = {Apicella, Andrea and Donnarumma, Francesco and Isgr{\`{o}}, Francesco and Prevete, Roberto},
booktitle = {Neural Networks},
doi = {10.1016/j.neunet.2021.01.026},
eprint = {2005.00817},
issn = {18792782},
keywords = {Activation functions,Learnable activation functions,Machine learning,Neural networks,Trainable activation functions},
pmid = {33611065},
title = {{A survey on modern trainable activation functions}},
year = {2021}
}


@article{Benvenuto1992,
abstract = {In this correspondence a recursive algorithm for updating the coefficients of a neural network structure for complex signals is presented. Various complex activation functions are considered and a practical definition is proposed. The method, associated to a mean-square-error criterion, yields the complex form of the conventional backpropagation algorithm. {\textcopyright} 1992 IEEE},
author = {Benvenuto, N. and Piazza, F.},
doi = {10.1109/78.127967},
issn = {19410476},
journal = {IEEE Transactions on Signal Processing},
title = {{On the Complex Backpropagation Algorithm}},
year = {1992}
}


@article{Dhanachandra2017,
abstract = {Image segmentation has been considered as the first step in the image processing. An efficient segmentation result would make it easier for further analysis of image processing. However, there exits many algorithms and approaches for image segmentation. Clustering is one of the commonly used image segmentation techniques. In this paper, we have briefly describe some of the clustering techniques and discuss some of the recent works by researchers on these techniques.},
author = {Dhanachandra, Nameirakpam and Chanu, Yambem Jina},
doi = {10.24018/ejers.2017.2.1.237},
journal = {European Journal of Engineering Research and Science},
title = {{A Survey on Image Segmentation Methods using Clustering Techniques}},
year = {2017}
}


@article{Pang2018,
abstract = {Network in network (NiN) is an effective instance and an important extension of deep convolutional neural network consisting of alternating convolutional layers and pooling layers. Instead of using a linear filter for convolution, NiN utilizes shallow multilayer perceptron (MLP), a nonlinear function, to replace the linear filter. Because of the powerfulness of MLP and {\$} 1\backslashtimes 1 {\$} convolutions in spatial domain, NiN has stronger ability of feature representation and hence results in better recognition performance. However, MLP itself consists of fully connected layers that give rise to a large number of parameters. In this paper, we propose to replace dense shallow MLP with sparse shallow MLP. One or more layers of the sparse shallow MLP are sparely connected in the channel dimension or channel-spatial domain. The proposed method is implemented by applying unshared convolution across the channel dimension and applying shared convolution across the spatial dimension in some computational layers. The proposed method is called convolution in convolution (CiC). The experimental results on the CIFAR10 data set, augmented CIFAR10 data set, and CIFAR100 data set demonstrate the effectiveness of the proposed CiC method.},
archivePrefix = {arXiv},
arxivId = {1603.06759},
author = {Pang, Yanwei and Sun, Manli and Jiang, Xiaoheng and Li, Xuelong},
doi = {10.1109/TNNLS.2017.2676130},
eprint = {1603.06759},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Convolution in convolution (CiC),Convolutional neural networks (CNNs),Image recognition,Network in network (NiN)},
pmid = {28328517},
title = {{Convolution in convolution for network in network}},
year = {2018}
}


@article{Muthukrishnan2011,
abstract = {Interpretation of image contents is one of the objectives in computer vision specifically in image processing. In this era it has received much awareness of researchers. In image interpretation the partition of the image into object and background is a severe step. Segmentation separates an image into its component regions or objects. Image segmentation t needs to segment the object from the background to read the image properly and identify the content of the image carefully. In this context, edge detection is a fundamental tool for image segmentation. In this paper an attempt is made to study the performance of most commonly used edge detection techniques for image segmentation and also the comparison of these techniques is carried out with an experiment by using MATLAB software.},
author = {Muthukrishnan, R and Radha, M},
doi = {10.5121/ijcsit.2011.3620},
issn = {09754660},
journal = {International Journal of Computer Science and Information Technology},
title = {{Edge Detection Techniques For Image Segmentation}},
year = {2011}
}


@article{Khaloo2017,
abstract = {Modern remote sensing technologies such as three-dimensional (3D) laser scanners and image-based 3D scene reconstruction are in increasing demand for applications in civil infrastructure design, maintenance, operation, and as-built construction verification. The complex nature of the 3D point clouds these technologies generate, as well as the often massive scale of the 3D data, make it inefficient and time consuming to manually analyze and manipulate point clouds, and highlights the need for automated analysis techniques. This paper presents one such technique, a new region growing algorithm for the automated segmentation of both planar and non-planar surfaces in point clouds. A core component of the algorithm is a new point normal estimation method, an essential task for many point cloud processing algorithms. The newly developed estimation method utilizes robust multivariate statistical outlier analysis for reliable normal estimation in complex 3D models, considering that these models often contain regions of varying surface roughness, a mixture of high curvature and low curvature regions, and sharp features. An adaptation of Mahalanobis distance, in which the mean vector and covariance matrix are derived from a high-breakdown multivariate location and scale estimator called Deterministic MM-estimator (DetMM) is used to find and discard outlier points prior to estimating the best local tangent plane around any point in a cloud. This approach is capable of more accurately estimating point normals located in highly curved regions or near sharp features. Thereafter, the estimated point normals serve a region growing segmentation algorithm that only requires a single input parameter, an improvement over existing methods which typically require two control parameters. The reliability and robustness of the normal estimation subroutine was compared against well-known normal estimation methods including the Minimum Volume Ellipsoid (MVE) and Minimum Covariance Determinant (MCD) estimators, along with Maximum Likelihood Sample Consensus (MLESAC). The overall region growing segmentation algorithm was then experimentally validated on several challenging 3D point clouds of real-world infrastructure systems. The results indicate that the developed approach performs more accurately and robustly in comparison with conventional region growing methods, particularly in the presence of sharp features, outliers and noise.},
author = {Khaloo, Ali and Lattanzi, David},
doi = {10.1016/j.aei.2017.07.002},
issn = {14740346},
journal = {Advanced Engineering Informatics},
keywords = {3D data processing,3D point cloud models,3D reconstruction,Computer vision,Normal estimation,Outliers,Robust estimation,Segmentation},
title = {{Robust normal estimation and region growing segmentation of infrastructure 3D point cloud models}},
year = {2017}
}


@article{Butchiraju2019,
abstract = {Object identification and multi-object picture separation are two firmly related processes and it can be enhanced when understood jointly by supporting data from one assignment to the next. Be that as it may, current best in object models are different portrayal for each space creation joint objects and leaving the categorization of numerous part of the scene uncertain. Picture element appearance highlights enable us to do well on classifying formless foundation classes, while the express portrayal of districts encourage the calculation of increasingly complex highlights essential for object detection. Vitally, our model gives a solitary bound together portrayal of the scene we clarify each picture elements of image and authorize it contains in the web between every random variable in our model.},
author = {Butchiraju, K. and Saikiran, Bandi},
doi = {10.35940/ijitee.K1353.0981119},
issn = {22783075},
journal = {International Journal of Innovative Technology and Exploring Engineering},
keywords = {And Image class prediction,Background,Context and Object modeling},
title = {{Region-based segmentation and object detection}},
year = {2019}
}


@article{Margaritondo2011,
abstract = {It is shown that an elementary semi-quantitative approach explains essential features of the X-ray free-electron laser mechanism, in particular those of the gain and saturation lengths. Using mathematical methods and derivations simpler than complete theories, this treatment reveals the basic physics that dominates the mechanism and makes it difficult to realise free-electron lasers for short wavelengths. This approach can be specifically useful for teachers at different levels and for colleagues interested in presenting X-ray free-electron lasers to non-specialized audiences. {\textcopyright} 2011 International Union of Crystallography.},
author = {Margaritondo, G. and {Rebernik Ribic}, Primoz},
doi = {10.1107/S090904951004896X},
issn = {09090495},
journal = {Journal of Synchrotron Radiation},
keywords = {SASE,X-ray laser,free-electron laser},
title = {{A simplified description of X-ray free-electron lasers}},
year = {2011}
}

@article{Wang2020,
abstract = {Image segmentation is a prerequisite for image processing. There are many methods for image segmentation, and as a result, a great number of methods for evaluating segmentation results have also been proposed. How to effectively evaluate the quality of image segmentation is very important. In this paper, the existing image segmentation quality evaluation methods are summarized, mainly including unsupervised methods and supervised methods. Based on hot issues, the application of metrics in natural, medical and remote sensing image evaluation is further outlined. In addition, an experimental comparison for some methods were carried out and the effectiveness of these methods was ranked. At the same time, the effectiveness of classical metrics for remote sensing and medical image evaluation is also verified.},
author = {Wang, Zhaobin and Wang, E. and Zhu, Ying},
doi = {10.1007/s10462-020-09830-9},
issn = {15737462},
journal = {Artificial Intelligence Review},
keywords = {Evaluation application,Image segmentation,Segmentation evaluation,Supervised evaluation,Unsupervised evaluation},
title = {{Image segmentation evaluation: a survey of methods}},
year = {2020}
}



@misc{Singh2020,
abstract = {Innovations in CT have been impressive among imaging and medical technologies in both the hardware and software domain. The range and speed of CT scanning improved from the introduction of multidetector-row CT scanners with wide-array detectors and faster gantry rotation speeds. To tackle concerns over rising radiation doses from its increasing use and to improve image quality, CT reconstruction techniques evolved from filtered back projection to commercial release of iterative reconstruction techniques, and recently, of deep learning (DL)-based image reconstruction. These newer reconstruction techniques enable improved or retained image quality versus filtered back projection at lower radiation doses. DL can aid in image reconstruction with training data without total reliance on the physical model of the imaging process, unique artifacts of PCD-CT due to charge sharing, K-escape, fluorescence x-ray emission, and pulse pileups can be handled in the data-driven fashion. With sufficiently reconstructed images, a well-designed network can be trained to upgrade image quality over a practical/clinical threshold or define new/killer applications. Besides, the much smaller detector pixel for PCD-CT can lead to huge computational costs with traditional model-based iterative reconstruction methods whereas deep networks can be much faster with training and validation. In this review, we present techniques, applications, uses, and limitations of deep learning-based image reconstruction methods in CT.},
author = {Singh, Ramandeep and Wu, Weiwen and Wang, Ge and Kalra, Mannudeep K.},
booktitle = {Physica Medica},
doi = {10.1016/j.ejmp.2020.11.012},
issn = {1724191X},
keywords = {Artificial Intelligence,Computed tomography,Deep learning,Image reconstruction},
pmid = {33246273},
title = {{Artificial intelligence in image reconstruction: The change is here}},
year = {2020}
}


@article{Lossau2019,
abstract = {Excellent image quality is a primary prerequisite for diagnostic non-invasive coronary CT angiography. Artifacts due to cardiac motion may interfere with detection and diagnosis of coronary artery disease and render subsequent treatment decisions more difficult. We propose deep-learning-based measures for coronary motion artifact recognition and quantification in order to assess the diagnostic reliability and image quality of coronary CT angiography images. More specifically, the application, steering and evaluation of motion compensation algorithms can be triggered by these measures. A Coronary Motion Forward Artifact model for CT data (CoMoFACT) is developed and applied to clinical cases with excellent image quality to introduce motion artifacts using simulated motion vector fields. The data required for supervised learning is generated by the CoMoFACT from 17 prospectively ECG-triggered clinical cases with controlled motion levels on a scale of 0–10. Convolutional neural networks achieve an accuracy of 93.3{\%} ± 1.8{\%} for the classification task of separating motion-free from motion-perturbed coronary cross-sectional image patches. The target motion level is predicted by a corresponding regression network with a mean absolute error of 1.12 ± 0.07. Transferability and generalization capabilities are demonstrated by motion artifact measurements on eight additional CCTA cases with real motion artifacts.},
author = {Lossau, T. and Nickisch, H. and Wissel, T. and Bippus, R. and Schmitt, H. and Morlock, M. and Grass, M.},
doi = {10.1016/j.media.2018.11.003},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Cardiac CT,Convolutional neural network,Coronary angiography,Motion artifact measure},
pmid = {30471464},
title = {{Motion artifact recognition and quantification in coronary CT angiography using convolutional neural networks}},
year = {2019}
}


@article{Guha2020,
abstract = {Osteoporosis, characterized by reduced bone mineral density and micro-architectural degeneration, significantly enhances fracture-risk. There are several viable methods for trabecular bone micro-imaging, which widely vary in terms of technology, reconstruction principle, spatial resolution, and acquisition time. We have performed an excised cadaveric bone specimen study to evaluate different computed tomography (CT)-imaging modalities for trabecular bone micro-structural analysis. Excised cadaveric bone specimens from the distal radius were scanned using micro-CT and four in vivo CT imaging modalities: high-resolution peripheral quantitative computed tomography (HR-pQCT), dental cone beam CT (CBCT), whole-body multi-row detector CT (MDCT), and extremity CBCT. A new algorithm was developed to optimize soft thresholding parameters for individual in vivo CT modalities for computing quantitative bone volume fraction maps. Finally, agreement of trabecular bone micro-structural measures, derived from different in vivo CT imaging, with reference measures from micro-CT imaging was examined. Observed values of most trabecular measures, including trabecular bone volume, network area, transverse and plate-rod micro-structure, thickness, and spacing, for in vivo CT modalities were higher than their micro-CT-based reference values. In general, HR-pQCT-based trabecular bone measures were closer to their reference values as compared to other in vivo CT modalities. Despite large differences in observed values of measures among modalities, high linear correlation (r ϵ [0.94 0.99]) was found between micro-CT and in vivo CT-derived measures of trabecular bone volume, transverse and plate micro-structural volume, and network area. All HR-pQCT-derived trabecular measures, except the erosion index, showed high correlation (r ϵ [0.91 0.99]). The plate-width measure showed a higher correlation (r ϵ [0.72 0.91]) among in vivo and micro-CT modalities than its counterpart binary plate-rod characterization-based measure erosion index (r ϵ [0.65 0.81]). Although a strong correlation was observed between micro-structural measures from in vivo and micro-CT imaging, large shifts in their values for in vivo modalities warrant proper scanner calibration prior to adopting in multi-site and longitudinal studies.},
author = {Guha, Indranil and Klintstr{\"{o}}m, Benjamin and Klintstr{\"{o}}m, Eva and Zhang, Xiaoliu and Smedby, {\"{O}}rjan and Moreno, Rodrigo and Saha, Punam K.},
doi = {10.1088/1361-6560/abc367},
issn = {13616560},
journal = {Physics in Medicine and Biology},
keywords = {Bone volume fraction,CBCT,CT imaging,HR-pQCT,MDCT,Micro-CT,Micro-structure,Osteoporosis,Soft-thresholding,Trabecular bone},
pmid = {33086213},
title = {{A comparative study of trabecular bone micro-structural measurements using different CT modalities}},
year = {2020}
}


@inproceedings{Kirz2009,
abstract = {We take a somewhat whimsical look at the history of X-ray microscopy, and extrapolate some trends into the future. {\textcopyright} 2009 IOP Publishing Ltd.},
author = {Kirz, J. and Jacobsen, C.},
booktitle = {Journal of Physics: Conference Series},
doi = {10.1088/1742-6596/186/1/012001},
issn = {17426588},
title = {{The history and future of X-ray microscopy}},
year = {2009}
}

@misc{VanderHeide2019,
abstract = {MRI is increasingly used in radiation oncology to facilitate tumor and organ-at-risk delineation and image guidance. In this review, we address issues of MRI that are relevant for radiation oncologists when interpreting MR images offered for radiotherapy. Whether MRI is used in combination with CT or in an MRI-only workflow, it is generally necessary to ensure that MR images are acquired in treatment position, using the positioning and fixation devices that are commonly applied in radiotherapy. For target delineation, often a series of separate image sets are used with distinct image contrasts, acquired within a single exam. MR images can suffer from image distortions. While this can be avoided with dedicated scan protocols, in a diagnostic setting geometrical fidelity is less relevant and is therefore less accounted for. Since geometrical fidelity is of utmost importance in radiation oncology, it requires dedicated scan protocols. The strong magnetic field of an MRI scanner and the use of radiofrequency radiation can cause safety hazards if not properly addressed. Safety screening is crucial for every patient and every operator prior to entering the MRI room.},
author = {van der Heide, Uulke A. and Frantzen-Steneker, Marloes and Astreinidou, Eleftheria and Nowee, Marlies E. and van Houdt, Petra J.},
booktitle = {Clinical and Translational Radiation Oncology},
doi = {10.1016/j.ctro.2019.04.008},
issn = {24056308},
keywords = {Geometrical fidelity,MR-guided radiotherapy,MRI,Radiotherapy planning},
title = {{MRI basics for radiation oncologists}},
year = {2019}
}


@misc{Kalpana2020,
abstract = {In the present world, the healthcare industries demand and costs may be increasing due the high population. It is a huge challenge for healthcare industries to analyse and classify disease. The available doctors cannot cover the all patients. The healthcare or medical informations are investigating and information management became a huge challenge because the complexity of problems. Data mining and data warehousing for Biological or medical problems is one of the most challenging issues in the real world. Human medical information are the mainly difficult of all biological information to classify to analyze the problem. In current senario, a number of peerreviewed research and reviw articles have deal with different aspects of healtcare data analytics applications. However, the shortfall of extensive and methodical clarification motivated us to build a extensive literature review and chalanges on this theme. In this paper, a systematic review of the comprehensive literature on healthcare intelligent data analytics.},
author = {Kalpana, C. and Booba, B.},
booktitle = {Journal of Critical Reviews},
doi = {10.31838/jcr.07.06.09},
issn = {23945125},
keywords = {Data Development,Intelligent Decision-making,Medical Data Analysis},
title = {{Intelligent medical data analytics: A crucial challenges {\&} reviews}},
year = {2020}
}


@misc{Litjens2017,
abstract = {Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field, most of which appeared in the last year. We survey the use of deep learning for image classification, object detection, segmentation, registration, and other tasks. Concise overviews are provided of studies per application area: neuro, retinal, pulmonary, digital pathology, breast, cardiac, abdominal, musculoskeletal. We end with a summary of the current state-of-the-art, a critical discussion of open challenges and directions for future research.},
archivePrefix = {arXiv},
arxivId = {1702.05747},
author = {Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and van der Laak, Jeroen A.W.M. and van Ginneken, Bram and S{\'{a}}nchez, Clara I.},
booktitle = {Medical Image Analysis},
doi = {10.1016/j.media.2017.07.005},
eprint = {1702.05747},
issn = {13618423},
keywords = {Convolutional neural networks,Deep learning,Medical imaging,Survey},
pmid = {28778026},
title = {{A survey on deep learning in medical image analysis}},
year = {2017}
}


@inproceedings{Korez2016,
abstract = {We propose an automated method for supervised segmentation of vertebral bodies (VBs) from three-dimensional (3D) magnetic resonance (MR) spine images that is based on coupling deformable models with convolutional neural networks (CNNs). We designed a 3D CNN architecture that learns the appearance from a training set of VBs to generate 3D spatial VB probability maps,which guide deformable models towards VB boundaries. The proposed method was applied to segment 161 VBs from 3D MR spine images of 23 subjects,and the results were compared to reference segmentations. By yielding an overall Dice similarity coefficient of 93.4±1.7{\%},mean symmetric surface distance of 0.54±0.14mm and Hausdorff distance of 3.83±1.04 mm,the proposed method proved superior to existing VB segmentation methods.},
author = {Korez, Robert and Likar, Bo{\v{s}}tjan and Pernu{\v{s}}, Franjo and Vrtovec, Toma{\v{z}}},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-46723-8_50},
isbn = {9783319467221},
issn = {16113349},
title = {{Model-based segmentation of vertebral bodies from MR images with 3D CNNS}},
year = {2016}
}


@inproceedings{Janssens2018,
abstract = {We present a method to address the challenging problem of segmentation of lumbar vertebrae from CT images acquired with varying fields of view. Our method is based on cascaded 3D Fully Convolutional Networks (FCNs) consisting of a localization FCN and a segmentation FCN. More specifically, in the first step we train a regression 3D FCN (we call it 'LocalizationNet') to find the bounding box of the lumbar region. After that, a 3D U-net like FCN (we call it 'Segmentation-Net') is then developed, which after training, can perform a pixel-wise multi-class segmentation to map a cropped lumber region volumetric data to its volume-wise labels. Evaluated on publicly available datasets, our method achieved an average Dice coefficient of 95.77 ± 0.81{\%} and an average symmetric surface distance of 0.37 ± 0.06 mm.},
archivePrefix = {arXiv},
arxivId = {1712.01509},
author = {Janssens, Rens and Zeng, Guodong and Zheng, Guoyan},
booktitle = {Proceedings - International Symposium on Biomedical Imaging},
doi = {10.1109/ISBI.2018.8363715},
eprint = {1712.01509},
isbn = {9781538636367},
issn = {19458452},
keywords = {CT,Fully Convolutional Networks,Lumbar vertebrae,Segmentation},
title = {{Fully automatic segmentation of lumbar vertebrae from CT images using cascaded 3D fully convolutional networks}},
year = {2018}
}


@inproceedings{Sekuboyina2018,
abstract = {Accurate segmentation of the spine in computed tomography (CT) images is mandatory for quantitative analysis, e.g. in osteoporosis, but remains challenging due to high variability in vertebral morphology and spinal anatomy among patients. Conventionally, spine segmentation was performed by model-based techniques employing spine atlases or statistical shape models. We argue that such approaches, even though intuitive, fail to address clinical abnormalities such as vertebral fractures, scoliosis, etc. We propose a novel deep learning-based method for segmenting the spine, which does not rely on any pre-defined shape model. We employ two networks: one for localisation and another for segmentation. Since a typical spine CT scan cannot be processed at once owing to its large dimensions, we find that both nets are essential to work towards a perfect segmentation. We evaluate our framework on three datasets containing healthy and fractured cases: two private and one public. Our approach achieves a mean Dice coefficient of {\~{}}0.87, which is comparable but not higher than the state-of-art model-based approaches. However, we show that our approach handles degenerate cases more accurately.},
author = {Sekuboyina, Anjany and Kuka{\v{c}}ka, Jan and Kirschke, Jan S. and Menze, Bjoern H. and Valentinitsch, Alexander},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-74113-0_10},
isbn = {9783319741123},
issn = {16113349},
keywords = {Automated segmentation,Deep learning,Fully convolutional network,Spine segmentation},
title = {{Attention-driven deep learning for pathological spine segmentation}},
year = {2018}
}

@article{Payer2019,
abstract = {In many medical image analysis applications, only a limited amount of training data is available due to the costs of image acquisition and the large manual annotation effort required from experts. Training recent state-of-the-art machine learning methods like convolutional neural networks (CNNs) from small datasets is a challenging task. In this work on anatomical landmark localization, we propose a CNN architecture that learns to split the localization task into two simpler sub-problems, reducing the overall need for large training datasets. Our fully convolutional SpatialConfiguration-Net (SCN) learns this simplification due to multiplying the heatmap predictions of its two components and by training the network in an end-to-end manner. Thus, the SCN dedicates one component to locally accurate but ambiguous candidate predictions, while the other component improves robustness to ambiguities by incorporating the spatial configuration of landmarks. In our extensive experimental evaluation, we show that the proposed SCN outperforms related methods in terms of landmark localization error on a variety of size-limited 2D and 3D landmark localization datasets, i.e., hand radiographs, lateral cephalograms, hand MRIs, and spine CTs.},
archivePrefix = {arXiv},
arxivId = {1908.00748},
author = {Payer, Christian and {\v{S}}tern, Darko and Bischof, Horst and Urschler, Martin},
doi = {10.1016/j.media.2019.03.007},
eprint = {1908.00748},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Anatomical landmarks,Fully convolutional networks,Heatmap regression,Localization},
pmid = {30947144},
title = {{Integrating spatial configuration into heatmap regression based CNNs for landmark localization}},
year = {2019}
}


@inproceedings{Yang2017,
abstract = {Automatic localization and labeling of vertebra in 3D medical images plays an important role in many clinical tasks, including pathological diagnosis, surgical planning and postoperative assessment. However, the unusual conditions of pathological cases, such as the abnormal spine curvature, bright visual imaging artifacts caused by metal implants, and the limited field of view, increase the difficulties of accurate localization. In this paper, we propose an automatic and fast algorithm to localize and label the vertebra centroids in 3D CT volumes. First, we deploy a deep image-to-image network (DI2IN) to initialize vertebra locations, employing the convolutional encoder-decoder architecture together with multi-level feature concatenation and deep supervision. Next, the centroid probability maps from DI2IN are iteratively evolved with the message passing schemes based on the mutual relation of vertebra centroids. Finally, the localization results are refined with sparsity regularization. The proposed method is evaluated on a public dataset of 302 spine CT volumes with various pathologies. Our method outperforms other state-of-the-art methods in terms of localization accuracy. The run time is around 3 seconds on average per case. To further boost the performance, we retrain the DI2IN on additional 1000+ 3D CT volumes from different patients. To the best of our knowledge, this is the first time more than 1000 3D CT volumes with expert annotation are adopted in experiments for the anatomic landmark detection tasks. Our experimental results show that training with such a large dataset significantly improves the performance and the overall identification rate, for the first time by our knowledge, reaches 90{\%}.},
author = {Yang, Dong and Xiong, Tao and Xu, Daguang and Huang, Qiangui and Liu, David and Zhou, S. Kevin and Xu, Zhoubing and Park, Jin Hyeong and Chen, Mingqing and Tran, Trac D. and Chin, Sang Peter and Metaxas, Dimitris and Comaniciu, Dorin},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-59050-9_50},
isbn = {9783319590493},
issn = {16113349},
title = {{Automatic vertebra labeling in large-scale 3D CT using deep image-to-image network with message passing and sparsity regularization}},
year = {2017}
}


@inproceedings{Bromiley2016,
abstract = {We describe a system for fully automatic vertebra localisation and segmentation in 3D CT volumes containing arbitrary regions of the spine, with the aim of detecting osteoporotic fractures. To avoid the difficulties of high-resolution manual annotation on overlapping structures in 3D, the system consists of several 2D operations. First, a Random Forest regressor is used to localise the spinal midplane in a coronal maximum intensity projection. A 2D sagittal image showing the midplane is then produced. A second set of regressors are used to localise each vertebral body in this image. Finally, a Random Forest Regression Voting Constrained Local Model is used to segment each detected vertebra. The system was evaluated on 402 CT volumes. 83{\%} of vertebrae between T4 and L4 were detected and, of these, 97{\%} were segmented with a mean error of less than or equal to 1mm. A simple classifier was applied to perform a fracture/non-fracture classification for each image, achieving 69{\%} recall at 70{\%} precision.},
author = {Bromiley, Paul A. and Kariki, Eleni P. and Adams, Judith E. and Cootes, Timothy F.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-55050-3_5},
isbn = {9783319550497},
issn = {16113349},
title = {{Fully automatic localisation of vertebrae in CT images using random forest regression voting}},
year = {2016}
}


@article{Ibragimov2017,
abstract = {Computerized segmentation of pathological structures in medical images is challenging, as, in addition to unclear image boundaries, image artifacts, and traces of surgical activities, the shape of pathological structures may be very different from the shape of normal structures. Even if a sufficient number of pathological training samples are collected, statistical shape modeling cannot always capture shape features of pathological samples as they may be suppressed by shape features of a considerably larger number of healthy samples. At the same time, landmarking can be efficient in analyzing pathological structures but often lacks robustness. In this paper, we combine the advantages of landmark detection and deformable models into a novel supervised multi-energy segmentation framework that can efficiently segment structures with pathological shape. The framework adopts the theory of Laplacian shape editing, that was introduced in the field of computer graphics, so that the limitations of statistical shape modeling are avoided. The performance of the proposed framework was validated by segmenting fractured lumbar vertebrae from 3-D computed tomography images, atrophic corpora callosa from 2-D magnetic resonance (MR) cross-sections and cancerous prostates from 3D MR images, resulting respectively in a Dice coefficient of 84.7 ± 5.0{\%}, 85.3 ± 4.8{\%} and 78.3 ± 5.1{\%}, and boundary distance of 1.14 ± 0.49mm, 1.42 ± 0.45mm and 2.27 ± 0.52mm. The obtained results were shown to be superior in comparison to existing deformable model-based segmentation algorithms.},
author = {Ibragimov, Bulat and Korez, Robert and Likar, Bostjan and Pernus, Franjo and Xing, Lei and Vrtovec, Tomaz},
doi = {10.1109/TMI.2017.2667578},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Laplacian mesh editing,corpus callosum segmentation,deformablemodels,landmark detection,pathology analysis,prostate segmentation,vertebra segmentation},
pmid = {28207388},
title = {{Segmentation of Pathological Structures by Landmark-Assisted Deformable Models}},
year = {2017}
}


@inproceedings{Payer2020,
abstract = {Localization and segmentation of vertebral bodies from spine CT volumes are crucial for pathological diagnosis, surgical planning, and postoperative assessment. However, fully automatic analysis of spine CT volumes is difficult due to the anatomical variation of pathologies, noise caused by screws and implants, and the large range of different field-of-views. We propose a fully automatic coarse to fine approach for vertebrae localization and segmentation based on fully convolutional CNNs. In a three-step approach, at first, a U-Net localizes the rough position of the spine. Then, the SpatialConfiguration-Net performs vertebrae localization and identification using heatmap regression. Finally, a U-Net performs binary segmentation of each identified vertebrae in a high resolution, before merging the individual predictions into the resulting multi-label vertebrae segmentation. The evaluation shows top performance of our approach, ranking first place and winning the MICCAI 2019 Large Scale Vertebrae Segmentation Challenge (VerSe 2019).},
author = {Payer, Christian and {\v{S}}tern, Darko and Bischof, Horst and Urschler, Martin},
booktitle = {VISIGRAPP 2020 - Proceedings of the 15th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
doi = {10.5220/0008975201240133},
isbn = {9789897584022},
keywords = {SpatialConfiguration-Net,U-Net,VerSe 2019 Challenge,Vertebrae Localization,Vertebrae Segmentation},
title = {{Coarse to fine vertebrae localization and segmentation with spatialconfiguration-Net and U-Net}},
year = {2020}
}


@article{Lessmann2019,
abstract = {Precise segmentation and anatomical identification of the vertebrae provides the basis for automatic analysis of the spine, such as detection of vertebral compression fractures or other abnormalities. Most dedicated spine CT and MR scans as well as scans of the chest, abdomen or neck cover only part of the spine. Segmentation and identification should therefore not rely on the visibility of certain vertebrae or a certain number of vertebrae. We propose an iterative instance segmentation approach that uses a fully convolutional neural network to segment and label vertebrae one after the other, independently of the number of visible vertebrae. This instance-by-instance segmentation is enabled by combining the network with a memory component that retains information about already segmented vertebrae. The network iteratively analyzes image patches, using information from both image and memory to search for the next vertebra. To efficiently traverse the image, we include the prior knowledge that the vertebrae are always located next to each other, which is used to follow the vertebral column. The network concurrently performs multiple tasks, which are segmentation of a vertebra, regression of its anatomical label and prediction whether the vertebra is completely visible in the image, which allows to exclude incompletely visible vertebrae from further analyses. The predicted anatomical labels of the individual vertebrae are additionally refined with a maximum likelihood approach, choosing the overall most likely labeling if all detected vertebrae are taken into account. This method was evaluated with five diverse datasets, including multiple modalities (CT and MR), various fields of view and coverages of different sections of the spine, and a particularly challenging set of low-dose chest CT scans. For vertebra segmentation, the average Dice score was 94.9 ± 2.1{\%} with an average absolute symmetric surface distance of 0.2 ± 10.1mm. The anatomical identification had an accuracy of 93{\%}, corresponding to a single case with mislabeled vertebrae. Vertebrae were classified as completely or incompletely visible with an accuracy of 97{\%}. The proposed iterative segmentation method compares favorably with state-of-the-art methods and is fast, flexible and generalizable.},
archivePrefix = {arXiv},
arxivId = {1804.04383},
author = {Lessmann, Nikolas and van Ginneken, Bram and de Jong, Pim A. and I{\v{s}}gum, Ivana},
doi = {10.1016/j.media.2019.02.005},
eprint = {1804.04383},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Deep learning,Iterative instance segmentation,Vertebra identification,Vertebra segmentation},
pmid = {30771712},
title = {{Iterative fully convolutional neural networks for automatic vertebra segmentation and identification}},
year = {2019}
}
