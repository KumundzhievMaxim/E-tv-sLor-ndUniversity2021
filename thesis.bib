% general nuclear imaging
@Book{oftankonyv,
 author = {Berczi, Viktor and Karlinger, Kinga and Kári, Béla and Légrády, Dávid and Czifrus, Szabolcs},
 title = {Medical Imaging},
 publisher = {Semmelweis University, Faculty of Medicine, Department of Radiology, Nuclear Medical Center and Budapest University of Technology and Economics, Faculty of Natural Sciences, Institute of Nuclear Technique},
 year = {2019},
 address = {Budapest},
 isbn = {9789633130667}
}

@Book{aarsvold2004emission,
 author = {Aarsvold, John},
 title = {Emission Tomography : the Fundamentals of Pet and Spect},
 publisher = {Elsevier},
 year = {2004},
 address = {Burlington},
 isbn = {9780080521879}
 }

@article{Jaszczak1981,
  doi = {10.1109/tns.1981.4331143},
  url = {https://doi.org/10.1109/tns.1981.4331143},
  year = {1981},
  month = feb,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {28},
  number = {1},
  pages = {69--80},
  author = {Ronald J. Jaszczak and R. Edward Coleman and Frank R. Whitehead},
  title = {Physical Factors Affecting Quantitative Measurements Using Camera-Based Single Photon Emission Computed Tomography (Spect)},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Kay1994,
  doi = {10.1177/096228029400300102},
  url = {https://doi.org/10.1177/096228029400300102},
  year = {1994},
  month = mar,
  publisher = {{SAGE} Publications},
  volume = {3},
  number = {1},
  pages = {5--21},
  author = {Jim Kay},
  title = {Statistical models for {PET} and {SPECT} data},
  journal = {Statistical Methods in Medical Research}
}

% monte carlo 
@book{Lux2018,
  doi = {10.1201/9781351074834},
  url = {https://doi.org/10.1201/9781351074834},
  year = {2018},
  month = may,
  publisher = {{CRC} Press},
  author = {Iv{\'{a}}n Lux and L{\'{a}}szl{\'{o}} Koblinger},
  title = {Monte Carlo Particle Transport Methods: Neutron and Photon Calculations}
}

@book{seco_monte_2016,
	address = {Boca Raton [etc.},
	title = {Monte {Carlo} techniques in radiation therapy},
	isbn = {9781138199903 9781466507920},
	language = {English},
	publisher = {CRC Press},
	author = {Seco, Joao and Verhaegen, Frank and {CRC Press}},
	year = {2016},
	note = {OCLC: 1000033162}
}

@Book{dupree2002a,
 author = {Dupree, Stephen},
 title = {A Monte Carlo Primer : a Practical Approach to Radiation Transport},
 publisher = {Springer US Imprint Springer},
 year = {2002},
 address = {Boston, MA},
 isbn = {978-1-4419-8491-3}
 }

% recon
@article{Shepp1974,
  doi = {10.1109/tns.1974.6499235},
  url = {https://doi.org/10.1109/tns.1974.6499235},
  year = {1974},
  month = jun,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {21},
  number = {3},
  pages = {21--43},
  author = {L. A. Shepp and B. F. Logan},
  title = {The Fourier reconstruction of a head section},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Shepp1982,
  doi = {10.1109/tmi.1982.4307558},
  url = {https://doi.org/10.1109/tmi.1982.4307558},
  year = {1982},
  month = oct,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {1},
  number = {2},
  pages = {113--122},
  author = {L. A. Shepp and Y. Vardi},
  title = {Maximum Likelihood Reconstruction for Emission Tomography},
  journal = {{IEEE} Transactions on Medical Imaging}
}

@article{Chornoboy1990,
  doi = {10.1109/42.52987},
  url = {https://doi.org/10.1109/42.52987},
  year = {1990},
  month = mar,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {9},
  number = {1},
  pages = {99--110},
  author = {E.S. Chornoboy and C.J. Chen and M.I. Miller and T.R. Miller and D.L. Snyder},
  title = {An evaluation of maximum likelihood reconstruction for {SPECT}},
  journal = {{IEEE} Transactions on Medical Imaging}
}

@article{Green1990,
  doi = {10.1109/42.52985},
  url = {https://doi.org/10.1109/42.52985},
  year = {1990},
  month = mar,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {9},
  number = {1},
  pages = {84--93},
  author = {P.J. Green},
  title = {Bayesian reconstructions from emission tomography data using a modified {EM} algorithm},
  journal = {{IEEE} Transactions on Medical Imaging}
}

@article{Green1990_2,
  doi = {10.1111/j.2517-6161.1990.tb01798.x},
  url = {https://doi.org/10.1111/j.2517-6161.1990.tb01798.x},
  year = {1990},
  month = jul,
  publisher = {Wiley},
  volume = {52},
  number = {3},
  pages = {443--452},
  author = {Peter J. Green},
  title = {On Use of the Em Algorithm for Penalized Likelihood Estimation},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)}
}

@article{Hudson1994,
  doi = {10.1109/42.363108},
  url = {https://doi.org/10.1109/42.363108},
  year = {1994},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {13},
  number = {4},
  pages = {601--609},
  author = {H.M. Hudson and R.S. Larkin},
  title = {Accelerated image reconstruction using ordered subsets of projection data},
  journal = {{IEEE} Transactions on Medical Imaging}
}

@article{DiBella1996,
  doi = {10.1109/23.552756},
  url = {https://doi.org/10.1109/23.552756},
  year = {1996},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {43},
  number = {6},
  pages = {3370--3376},
  author = {E.V.R. Di Bella and A.B. Barclay and R.L. Eisner and R.W. Schafer},
  title = {A comparison of rotation-based methods for iterative reconstruction algorithms},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Wallis1997,
  doi = {10.1109/42.552061},
  url = {https://doi.org/10.1109/42.552061},
  year = {1997},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {16},
  number = {1},
  pages = {118--123},
  author = {J.W. Wallis and T.R. Miller},
  title = {An optimal rotator for iterative reconstruction},
  journal = {{IEEE} Transactions on Medical Imaging}
}

@article{Kamphuis1997,
  doi = {10.1007/s002590050188},
  url = {https://doi.org/10.1007/s002590050188},
  year = {1997},
  month = dec,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {25},
  number = {1},
  pages = {8--18},
  author = {Chris Kamphuis and Freek J. Beekman and Peter P. van Rijk and Max A. Viergever},
  title = {Dual matrix ordered subsets reconstruction for accelerated 3D scatter compensation in single-photon emission tomography},
  journal = {European Journal of Nuclear Medicine and Molecular Imaging}
}

@article{Panin1999,
  doi = {10.1109/23.819305},
  url = {https://doi.org/10.1109/23.819305},
  year = {1999},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {46},
  number = {6},
  pages = {2202--2210},
  author = {V.Y. Panin and G.L. Zeng and G.T. Gullberg},
  title = {Total variation regulated {EM} algorithm [{SPECT} reconstruction]},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Persson2001,
  doi = {10.1016/s0168-9002(01)00962-7},
  url = {https://doi.org/10.1016/s0168-9002(01)00962-7},
  year = {2001},
  month = sep,
  publisher = {Elsevier {BV}},
  volume = {471},
  number = {1-2},
  pages = {98--102},
  author = {Mikael Persson and Dianna Bone and H{\aa}kan Elmqvist},
  title = {Three-dimensional total variation norm for {SPECT} reconstruction},
  journal = {Nuclear Instruments and Methods in Physics Research Section A: Accelerators,  Spectrometers,  Detectors and Associated Equipment}
}

 @inproceedings{Bergner,
  doi = {10.1109/nssmic.2005.1596967},
  url = {https://doi.org/10.1109/nssmic.2005.1596967},
  publisher = {{IEEE}},
  author = {S. Bergner and E. Dagenais and A. Celler and T. Moeller},
  title = {Using the Physics-based Rendering Toolkit for Medical Reconstruction},
  booktitle = {{IEEE} Nuclear Science Symposium Conference Record,  2005}
}

% monte carlo spect
@article{Beck1982,
  doi = {10.1109/tns.1982.4335896},
  url = {https://doi.org/10.1109/tns.1982.4335896},
  year = {1982},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {29},
  number = {1},
  pages = {506--511},
  author = {John W. Beck and Ronald J. Jaszczak and R. Edward Coleman and C. Frank Starmer and Loren W. Nolte},
  title = {Analysis of {SPECT} including Scatter and Attenuation Using Sophisticated Monte Carlo Modeling Methods},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Floyd1984,
  doi = {10.1088/0031-9155/29/10/005},
  url = {https://doi.org/10.1088/0031-9155/29/10/005},
  year = {1984},
  month = oct,
  publisher = {{IOP} Publishing},
  volume = {29},
  number = {10},
  pages = {1217--1230},
  author = {C E Floyd and R J Jaszczak and C C Harris and R E Coleman},
  title = {Energy and spatial distribution of multiple order Compton scatter in {SPECT}: a Monte Carlo investigation},
  journal = {Physics in Medicine and Biology}
}

@article{Ljungberg1989,
  doi = {10.1016/0169-2607(89)90111-9},
  url = {https://doi.org/10.1016/0169-2607(89)90111-9},
  year = {1989},
  month = aug,
  publisher = {Elsevier {BV}},
  volume = {29},
  number = {4},
  pages = {257--272},
  author = {Michael Ljungberg and Sven-Erik Strand},
  title = {A Monte Carlo program for the simulation of scintillation camera characteristics},
  journal = {Computer Methods and Programs in Biomedicine}
}

@Article{pmid2045947,
   Author="Ljungberg, M.  and Strand, S. E.",
   Title="{Attenuation and scatter correction in SPECT for sources in a nonhomogeneous object: a Monte Carlo study}",
   Journal="J. Nucl. Med.",
   Year="1991",
   Volume="32",
   Number="6",
   Pages="1278--1284",
   Month="Jun"
}

@article{Haynor1991,
  doi = {10.1118/1.596615},
  url = {https://doi.org/10.1118/1.596615},
  year = {1991},
  month = sep,
  publisher = {Wiley},
  volume = {18},
  number = {5},
  pages = {990--1001},
  author = {David R. Haynor and Robert L. Harrison and Thomas K. Lewellen},
  title = {The use of importance sampling techniques to improve the efficiency of photon tracking in emission tomography simulations},
  journal = {Medical Physics}
}

@Book{ljungberg1998monte,
 author = {Ljungberg, Michael},
 title = {Monte Carlo calculations in nuclear medicine : applications in diagnostic imaging},
 publisher = {Institute of Physics Pub},
 year = {1998},
 address = {Bristol Philadelphia},
 isbn = {9780750304795}
 }

@article{Song2005,
  doi = {10.1088/0031-9155/50/8/011},
  url = {https://doi.org/10.1088/0031-9155/50/8/011},
  year = {2005},
  month = apr,
  publisher = {{IOP} Publishing},
  volume = {50},
  number = {8},
  pages = {1791--1804},
  author = {X Song and W P Segars and Y Du and B M W Tsui and E C Frey},
  title = {Fast modelling of the collimator{\textendash}detector response in Monte Carlo simulation of {SPECT} imaging using the angular response function},
  journal = {Physics in Medicine and Biology}
}

% scatter correction
@article{Beekman1999,
  doi = {10.1088/0031-9155/44/8/402},
  url = {https://doi.org/10.1088/0031-9155/44/8/402},
  year = {1999},
  month = jul,
  publisher = {{IOP} Publishing},
  volume = {44},
  number = {8},
  pages = {N183--N192},
  author = {Freek J Beekman and Hugo W A M de Jong and Eddy T P Slijpen},
  title = {Efficient {SPECT} scatter calculation in non-uniform media using correlated Monte Carlo simulation},
  journal = {Physics in Medicine and Biology}
}

@article{Jong2001,
  doi = {10.1088/0031-9155/46/3/301},
  url = {https://doi.org/10.1088/0031-9155/46/3/301},
  year = {2001},
  month = jan,
  publisher = {{IOP} Publishing},
  volume = {46},
  number = {3},
  pages = {621--635},
  author = {Hugo W A M de Jong and Freek J Beekman},
  title = {Rapid {SPECT} simulation of downscatter in non-uniform media},
  journal = {Physics in Medicine and Biology}
}

@article{deJong2001,
  doi = {10.1109/23.910833},
  url = {https://doi.org/10.1109/23.910833},
  year = {2001},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {48},
  number = {1},
  pages = {58--64},
  author = {H.W.A.M. de Jong and E.T.P. Slijpen and F.J. Beekman},
  title = {Acceleration of Monte Carlo {SPECT} simulation using convolution-based forced detection},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Beekman2002,
  doi = {10.1109/tmi.2002.803130},
  url = {https://doi.org/10.1109/tmi.2002.803130},
  year = {2002},
  month = aug,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {21},
  number = {8},
  pages = {867--877},
  author = {F.J. Beekman and H.W.A.M. de Jong and S. van Geloven},
  title = {Efficient fully 3-D iterative {SPECT} reconstruction with Monte Carlo-based scatter compensation},
  journal = {{IEEE} Transactions on Medical Imaging}
}

@article{deWit2005,
  doi = {10.1109/tns.2005.858220},
  url = {https://doi.org/10.1109/tns.2005.858220},
  year = {2005},
  month = oct,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {52},
  number = {5},
  pages = {1365--1369},
  author = {T.C. de Wit and  Jianbin Xiao and F.J. Beekman},
  title = {Monte Carlo-based statistical {SPECT} reconstruction: influence of number of photon tracks},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Sohlberg2008,
  doi = {10.1088/0031-9155/53/14/n02},
  url = {https://doi.org/10.1088/0031-9155/53/14/n02},
  year = {2008},
  month = jun,
  publisher = {{IOP} Publishing},
  volume = {53},
  number = {14},
  pages = {N277--N285},
  author = {A Sohlberg and H Watabe and H Iida},
  title = {Acceleration of Monte Carlo-based scatter compensation for cardiac {SPECT}},
  journal = {Physics in Medicine and Biology}
}

@article{Hutton2011,
  doi = {10.1088/0031-9155/56/14/r01},
  url = {https://doi.org/10.1088/0031-9155/56/14/r01},
  year = {2011},
  month = jun,
  publisher = {{IOP} Publishing},
  volume = {56},
  number = {14},
  pages = {R85--R112},
  author = {Brian F Hutton and Ir{\`{e}}ne Buvat and Freek J Beekman},
  title = {Review and current status of {SPECT} scatter correction},
  journal = {Physics in Medicine and Biology}
}

% attenuation correction
@article{LaCroix1994,
  doi = {10.1109/23.340649},
  url = {https://doi.org/10.1109/23.340649},
  year = {1994},
  month = dec,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {41},
  number = {6},
  pages = {2793--2799},
  author = {K.J. LaCroix and B.M.W. Tsui and B.H. Hasegawa and J.K. Brown},
  title = {Investigation of the use of X-ray {CT} images for attenuation compensation in {SPECT}},
  journal = {{IEEE} Transactions on Nuclear Science}
}

@article{Patton2008,
  doi = {10.2967/jnmt.107.046839},
  url = {https://doi.org/10.2967/jnmt.107.046839},
  year = {2008},
  month = mar,
  publisher = {Society of Nuclear Medicine},
  volume = {36},
  number = {1},
  pages = {1--10},
  author = {J. A. Patton and T. G. Turkington},
  title = {{SPECT}/{CT} Physical Principles and Attenuation Correction},
  journal = {Journal of Nuclear Medicine Technology}
}

% CT to LAC
@inproceedings{inproceedings,
author = {Crawley, Edward and Evans, William and Owen, Glynn},
year = {1985},
month = {01},
pages = {93},
title = {Abstract: The measurement of effective energy and linear attenuation coefficient in a x-ray CT scanner},
volume = {30},
journal = {Physics in Medicine and Biology}
}

@article{Watanabe1999,
  doi = {10.1088/0031-9155/44/9/308},
  url = {https://doi.org/10.1088/0031-9155/44/9/308},
  year = {1999},
  month = aug,
  publisher = {{IOP} Publishing},
  volume = {44},
  number = {9},
  pages = {2201--2211},
  author = {Yoichi Watanabe},
  title = {Derivation of linear attenuation coefficients from {CT} numbers for low-energy photons},
  journal = {Physics in Medicine and Biology}
}

@article{ChuanyongBai2003,
  doi = {10.1109/tns.2003.817281},
  url = {https://doi.org/10.1109/tns.2003.817281},
  year = {2003},
  month = oct,
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  volume = {50},
  number = {5},
  pages = {1510--1515},
  author = {Chuanyong Bai and  Ling Shao and A.J. Da Silva and  Zuo Zhao},
  title = {A generalized model for the conversion from ct numbers to linear attenuation coefficients},
  journal = {{IEEE} Transactions on Nuclear Science}
}

% databases
@article{White1987,
  doi = {10.1259/0007-1285-60-717-907},
  url = {https://doi.org/10.1259/0007-1285-60-717-907},
  year = {1987},
  month = sep,
  publisher = {British Institute of Radiology},
  volume = {60},
  number = {717},
  pages = {907--913},
  author = {D. R. White and H. Q. Woodard and S. M. Hammond},
  title = {Average soft-tissue and bone models for use in radiation dosimetry},
  journal = {The British Journal of Radiology}
}

@article{White1989,
  doi = {10.1093/jicru/os23.1.report44},
  url = {https://doi.org/10.1093/jicru/os23.1.report44},
  year = {1989},
  month = jan,
  publisher = {{SAGE} Publications},
  volume = {os23},
  number = {1},
  pages = {NP--NP},
  author = {D. R. White and J. Booz and R. V. Griffith and J. J. Spokas and I. J. Wilson},
  title = {Report 44},
  journal = {Journal of the International Commission on Radiation Units and Measurements}
}

@misc{xcom,
  doi = {10.18434/T48G6X},
  url = {http://www.nist.gov/pml/data/xcom/index.cfm},
  author = {Seltzer,  Stephen},
  language = {eng},
  title = {XCOM-Photon Cross Sections Database,  NIST Standard Reference Database 8},
  publisher = {National Institute of Standards and Technology},
  year = {1987}
}

%%%%%%%%%%%%%%%%
@inproceedings{Ronneberger2015,
abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-24574-4_28},
issn = {16113349},
title = {{U-net: Convolutional networks for biomedical image segmentation}},
volume = {9351},
year = {2015}
}

@article{Shapiro2001,
abstract = {A c hanging scene may be observed via a sequence of images. One might learn a golf swing by observing the motions of an expert with a video camera, or better understand root growth by observing the root using many images taken hours apart. Action phenomena observed over time can be due to the motion of objects or the observer or both. Changes in an im-age sequence provide features for detecting objects that are moving or for computing their trajectories. In case the viewer is moving through a relatively static world, image changes allow for computing the motion of the viewer in the world. Similarly changing pixels in an image provide an important feature for object detection and recognition. Motion can reveal the shape of an object as well as other characteristics, such as speed or function. Analysis of object motion over time may be the ultimate goal, for instance in controlling trac ow or in analyzing the gait of a person with a new prosthesis. Today, a h uge amount of videos are made to record events and structure of the world. It is necessary to have methods of segmenting these image sequences into meaningful events or scenes for easy access, analysis or editing. This chapter concentrates on detection of motion from 2D images and video sequences and the image analysis used to extract features. Methods for solution of the above applicaton problems are discussed. Analysis of 3D structure and motion derived from 2D images is discussed in Chapter 13.},
author = {Shapiro, Linda G. and Stockman, George C.},
isbn = {0-13-030796-3},
journal = {Computer Vision},
title = {{Motion from 2D Image Sequences}},
year = {2001}
}

@article{Kim2020,
abstract = {Recent state-of-the-art image segmentation algorithms are mostly based on deep neural networks, thanks to their high performance and fast computation time. However, these methods are usually trained in a supervised manner, which requires large number of high quality ground-truth segmentation masks. On the other hand, classical image segmentation approaches such as level-set methods are formulated in a self-supervised manner by minimizing energy functions such as Mumford-Shah functional, so they are still useful to help generate segmentation masks without labels. Unfortunately, these algorithms are usually computationally expensive and often have limitation in semantic segmentation. In this paper, we propose a novel loss function based on Mumford-Shah functional that can be used in deep-learning based image segmentation without or with small labeled data. This loss function is based on the observation that the softmax layer of deep neural networks has striking similarity to the characteristic function in the Mumford-Shah functional. We show that the new loss function enables semi-supervised and unsupervised segmentation. In addition, our loss function can also be used as a regularized function to enhance supervised semantic segmentation algorithms. Experimental results on multiple datasets demonstrate the effectiveness of the proposed method.},
archivePrefix = {arXiv},
arxivId = {1904.02872},
author = {Kim, Boah and Ye, Jong Chul},
doi = {10.1109/TIP.2019.2941265},
eprint = {1904.02872},
issn = {19410042},
journal = {IEEE Transactions on Image Processing},
keywords = {Mumford-Shah functional,Semi-supervised learning,image segmentation,unsupervised learning},
title = {{Mumford-shah loss functional for image segmentation with deep learning}},
year = {2020}
}

@article{Buda1992,
abstract = {Chirality is a property that is independent of its physical and chemical manifestations. It is therefore possible to quantify chirality without any reference to pseudoscalar observables. In this paper we propose a new measure of chirality that is based on Hausdorff s concept of distances between sets and that is a natural choice as a measure for molecular models that represent structures as sets of atomic coordinates. This Hausdorff chirality measure, a continuous and similarity-invariant function of an object's shape, is zero if and only if the object is achiral. We have applied this measure to study the chirality of tetrahedral shapes—classical models of tetracoordinate carbon atoms—and have identified the extremal (most chiral) shapes for every chiral subsymmetry of Td that can be realized by a tetrahedron. Our calculations show that the degree of chirality of the extremal objects increases with a decrease in symmetry, although the most symmetric chiral tetrahedron, with D2 symmetry, already possesses 87{\%} of the maximal chirality value available for tetrahedra, and that the shape of the most chiral tetrahedron, with C1 symmetry, is very close to that of the most chiral C2 tetrahedron. The properties and the applicability of the Hausdorff chirality measure are compared with those of other measures of chirality that are based on common-volume or root-mean-square approaches. {\textcopyright} 1992, American Chemical Society. All rights reserved.},
author = {Buda, Andrzej B. and Mislow, Kurt},
doi = {10.1021/ja00041a016},
issn = {15205126},
journal = {Journal of the American Chemical Society},
title = {{A Hausdorff Chirality Measure}},
year = {1992}
}

@article{Wu1982,
abstract = {This is a tutorial review on the Potts model aimed at bringing out in an organized fashion the essential and important properties of the standard Potts model. Emphasis is placed on exact and rigorous results, but other aspects of the problem are also described to achieve a unified perspective. Topics reviewed include the mean-field theory, duality relations, series expansions, critical properties, experimental realizations, and the relationship of the Potts model with other lattice-statistical problems. {\textcopyright} 1982 American Physical Society.},
author = {Wu, F. Y.},
doi = {10.1103/RevModPhys.54.235},
issn = {00346861},
journal = {Reviews of Modern Physics},
title = {{The Potts model}},
year = {1982}
}

@inproceedings{Zhang2018,
abstract = {Deep neural networks (DNNs) have achieved tremendous success in a variety of applications across many disciplines. Yet, their superior performance comes with the expensive cost of requiring correctly annotated large-scale datasets. Moreover, due to DNNs' rich capacity, errors in training labels can hamper performance. To combat this problem, mean absolute error (MAE) has recently been proposed as a noise-robust alternative to the commonly-used categorical cross entropy (CCE) loss. However, as we show in this paper, MAE can perform poorly with DNNs and challenging datasets. Here, we present a theoretically grounded set of noise-robust loss functions that can be seen as a generalization of MAE and CCE. Proposed loss functions can be readily applied with any existing DNN architecture and algorithm, while yielding good performance in a wide range of noisy label scenarios. We report results from experiments conducted with CIFAR-10, CIFAR-100 and FASHION-MNIST datasets and synthetically generated noisy labels.},
archivePrefix = {arXiv},
arxivId = {1805.07836},
author = {Zhang, Zhilu and Sabuncu, Mert R.},
booktitle = {Advances in Neural Information Processing Systems},
eprint = {1805.07836},
issn = {10495258},
title = {{Generalized cross entropy loss for training deep neural networks with noisy labels}},
year = {2018}
}

@article{Thada2013,
abstract = {A similarity coefficient represents the similarity between two documents, two queries, or one document and one query. The retrieved documents can also be ranked in the order of presumed importance. A similarity coefficient is a function which computes the degree of similarity between a pair of text objects. There are a large number of similarity coefficients proposed in the literature, because the best similarity measure doesn't exist (yet !). In this paper we do a comparative analysis for finding out the most relevant document for the given set of keyword by using three similarity coefficients viz Jaccard, Dice and Cosine coefficients. This we perform using genetic algorithm approach. Due to the randomized nature of genetic algorithm the best fitness value is the average of 10 runs of the same code for a fixed number of iterations.The similarity coefficient for a set of documents retrieved for a given query from Google are find out then average relevancy in terms of fitness values using similarity coefficients is calculated. In this paper we have averaged 10 different generations for each query by running the program 10 times for the fixed value of Probability of Crossover Pc=0.7 and Probability of Mutation Pm=0.01. The same experiment was conducted for 10 queries.},
author = {Thada, Vikas and Jaglan, Vivek},
journal = {International Journal of Innovations in Engineering and Technology},
title = {{Comparison of jaccard, dice, cosine similarity coefficient to find best fitness value for web retrieved documents using genetic algorithm}},
year = {2013}
}


@article{Liao2018,
abstract = {Automatic vertebrae identification and localization from arbitrary computed tomography (CT) images is challenging. Vertebrae usually share similar morphological appearance. Because of pathology and the arbitrary field-of-view of CT scans, one can hardly rely on the existence of some anchor vertebrae or parametric methods to model the appearance and shape. To solve the problem, we argue that: 1) one should make use of the short-range contextual information, such as the presence of some nearby organs (if any), to roughly estimate the target vertebrae; and 2) due to the unique anatomic structure of the spine column, vertebrae have fixed sequential order, which provides the important long-range contextual information to further calibrate the results. We propose a robust and efficient vertebrae identification and localization system that can inherently learn to incorporate both the short- and long-range contextual information in a supervised manner. To this end, we develop a multi-task 3-D fully convolutional neural network to effectively extract the short-range contextual information around the target vertebrae. For the long-range contextual information, we propose a multi-task bidirectional recurrent neural network to encode the spatial and contextual information among the vertebrae of the visible spine column. We demonstrate the effectiveness of the proposed approach on a challenging data set, and the experimental results show that our approach outperforms the state-of-the-art methods by a significant margin.},
archivePrefix = {arXiv},
arxivId = {1812.03500},
author = {Liao, Haofu and Mesfin, Addisu and Luo, Jiebo},
doi = {10.1109/TMI.2018.2798293},
eprint = {1812.03500},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Automatic vertebrae identification and localization,CT image,convolutional neural network,deep learning,multi-task learning,recurrent neural network},
pmid = {29727289},
title = {{Joint vertebrae identification and localization in spinal CT images by combining short- and long-range contextual information}},
year = {2018}
}


@article{Barker1996,
abstract = {This article discusses the use of the four main types of medical imaging, i.e. x-ray, radionuclide, ultrasound and magnetic resonance, and considers their relative merits. Important recent and possible future developments in image processing are also described. {\textcopyright} 1996.},
author = {Barker, M. C.J.},
doi = {10.1088/0031-9120/31/2/013},
issn = {13616552},
journal = {Physics Education},
title = {{Medical imaging}},
year = {1996}
}


@article{Ahlberg2005,
abstract = {Ichthyostega was the first Devonian tetrapod to be subject to a whole-body reconstruction. It remains, together with Acanthostega, one of only two Devonian tetrapods for which near-complete postcranial material is available. It is thus crucially important for our understanding of the earliest stages of tetrapod evolution and terrestrialization. Here we show a new reconstruction of Ichthyostega based on extensive re-examination of original material and augmented by recently collected specimens. Our reconstruction differs substantially from those previously published and reveals hitherto unrecognized regionalization in the vertebral column. Ichthyostega is the earliest vertebrate to show obvious adaptations for non-swimming locomotion. Uniquely among early tetrapods, the presacral vertebral column shows pronounced regionalization of neural arch morphology, suggesting that it was adapted for dorsoventral rather than lateral flexion. {\textcopyright} 2005 Nature Publishing Group.},
author = {Ahlberg, Per Erik and Clack, Jennifer A. and Blom, Henning},
doi = {10.1038/nature03893},
issn = {14764687},
journal = {Nature},
pmid = {16136143},
title = {{The axial skeleton of the Devonian tetrapod Ichthyostega}},
year = {2005}
}

@article{Pham2000,
abstract = {Image segmentation plays a crucial role in many medical-imaging applications, by automating or facilitating the delineation of anatomical structures and other regions of interest. We present a critical appraisal of the current status of semi-automated and automated methods for the segmentation of anatomical medical images. Terminology and important issues in image segmentation are first presented. Current segmentation approaches are then reviewed with an emphasis on the advantages and disadvantages of these methods for medical imaging applications. We conclude with a discussion on the future of image segmentation methods in biomedical research.},
author = {Pham, Dzung L. and Xu, Chenyang and Prince, Jerry L.},
doi = {10.1146/annurev.bioeng.2.1.315},
issn = {15239829},
journal = {Annual Review of Biomedical Engineering},
keywords = {Classification,Deformable models,Image processing,Magnetic resonance imaging,Medical imaging},
pmid = {11701515},
title = {{Current methods in medical image segmentation}},
year = {2000}
}

@inproceedings{Ronneberger2015,
abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
archivePrefix = {arXiv},
arxivId = {1505.04597},
author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-24574-4_28},
eprint = {1505.04597},
isbn = {9783319245737},
issn = {16113349},
title = {{U-net: Convolutional networks for biomedical image segmentation}},
year = {2015}
}

@article{Seeram2004,
abstract = {Digital image processing is now commonplace in radiology, nuclear medicine and sonography. This article outlines underlying principles and concepts of digital image processing. After completing this article, readers should be able to: List the limitations of film-based imaging. Identify major components of a digital imaging system. Describe the history and application areas of digital image processing. Discuss image representation and the fundamentals of digital image processing. Outline digital image processing techniques and processing operations used in selected imaging modalities. Explain the basic concepts and visualization tools used in 3-D and virtual reality imaging. Recognize medical imaging informatics as a new area of specialization for radiologic technologists.},
author = {Seeram, Euclid},
doi = {10.4324/9781315693125-12},
issn = {00338397},
journal = {Radiologic technology},
pmid = {15352557},
title = {{Digital image processing.}},
year = {2004}
}

@article{Duncan2000,
abstract = {The analysis of medical images has been woven into the fabric of the Pattern Analysis and Machine Intelligence (PAMI) community since the earliest days of these Transactions. Initially, the efforts in this area were seen as applying pattern analysis and computer vision techniques to another interesting dataset. However, over the last two to three decades, the unique nature of the problems presented within this area of study have led to the development of a new discipline in its own right. Examples of these include: the types of image information that are acquired, the fully three-dimensional image data, the nonrigid nature of object motion and deformation, and the statistical variation of both the underlying normal and abnormal ground truth. In this paper, we look at progress in the field over the last 20 years and suggest some of the challenges that remain for the years to come.},
author = {Duncan, James S. and Ayache, Nicholas},
doi = {10.1109/34.824822},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
title = {{Medical image analysis: Progress over two decades and the challenges ahead}},
year = {2000}
}


@article{Wang2020,
abstract = {Thyroid nodules have a high prevalence and a small percentage is malignant. Many non-invasive methods have been developed with the help of the Internet of Things to improve the detection rate of malignant nodules. These methods can be roughly categorized into two classes: radiomics based and deep learning based approaches. In general, convolutional neural networks based deep learning methods have achieved promising performance in many medical image analysis and classification applications; however, no existing comparison has been done between radiomics based and deep learning based approaches. Therefore, in this paper, we aim to compare the performance of radiomics and deep learning based methods for the classification of thyroid nodules from ultrasound images. On one hand, we developed a radiomics based method, which consists of extracting high throughput 302-dimensional statistical features from pre-processed images. Then dimension reduction was performed using mutual information and linear discriminant analysis respectively to achieve the final classification. On the other hand, a deep learning based method was also developed and tested by pre-training a VGG16 model with fine-tuning. Ultrasound images including 3120 images (1841 benign nodules and 1393 malignant nodules) from 1040 cases were retrospectively collected. The dataset was divided into 80{\%} training and 20{\%} testing data. The highest accuracies yielded on the testing data for radiomics and deep learning based methods were 66.81{\%} and 74.69{\%}, respectively. A comparison result demonstrated that the deep learning based method can achieve a better performance than using radiomics.},
author = {Wang, Yongfeng and Yue, Wenwen and Li, Xiaolong and Liu, Shuyu and Guo, Lehang and Xu, Huixiong and Zhang, Heye and Yang, Guang},
doi = {10.1109/ACCESS.2020.2980290},
issn = {21693536},
journal = {IEEE Access},
keywords = {Ultrasound images,convolutional neural network,nodule classification,radiomics,thyroid cancer,thyroid nodule},
title = {{Comparison Study of Radiomics and Deep Learning-Based Methods for Thyroid Nodules Classification Using Ultrasound Images}},
year = {2020}
}


@misc{Anwar2018,
abstract = {The science of solving clinical problems by analyzing images generated in clinical practice is known as medical image analysis. The aim is to extract information in an affective and efficient manner for improved clinical diagnosis. The recent advances in the field of biomedical engineering have made medical image analysis one of the top research and development area. One of the reasons for this advancement is the application of machine learning techniques for the analysis of medical images. Deep learning is successfully used as a tool for machine learning, where a neural network is capable of automatically learning features. This is in contrast to those methods where traditionally hand crafted features are used. The selection and calculation of these features is a challenging task. Among deep learning techniques, deep convolutional networks are actively used for the purpose of medical image analysis. This includes application areas such as segmentation, abnormality detection, disease classification, computer aided diagnosis and retrieval. In this study, a comprehensive review of the current state-of-the-art in medical image analysis using deep convolutional networks is presented. The challenges and potential of these techniques are also highlighted.},
archivePrefix = {arXiv},
arxivId = {1709.02250},
author = {Anwar, Syed Muhammad and Majid, Muhammad and Qayyum, Adnan and Awais, Muhammad and Alnowami, Majdi and Khan, Muhammad Khurram},
booktitle = {Journal of Medical Systems},
doi = {10.1007/s10916-018-1088-1},
eprint = {1709.02250},
issn = {1573689X},
keywords = {Classification,Computer aided diagnosis,Convolutional neural network,Medical image analysis,Segmentation},
pmid = {30298337},
title = {{Medical Image Analysis using Convolutional Neural Networks: A Review}},
year = {2018}
}


@inproceedings{Suzani2015,
abstract = {{\textcopyright} 2015 SPIE. This paper proposes an automatic method for vertebra localization, labeling, and segmentation in multi-slice Magnetic Resonance (MR) images. Prior work in this area on MR images mostly requires user interaction while our method is fully automatic. Cubic intensity-based features are extracted from image voxels. A deep learning approach is used for simultaneous localization and identification of vertebrae. The localized points are refined by local thresholding in the region of the detected vertebral column. Thereafter, a statistical multi-vertebrae model is initialized on the localized vertebrae. An iterative Expectation Maximization technique is used to register the vertebral body of the model to the image edges and obtain a segmentation of the lumbar vertebral bodies. The method is evaluated by applying to nine volumetric MR images of the spine. The results demonstrate 100{\%} vertebra identification and a mean surface error of below 2.8 mm for 3D segmentation. Computation time is less than three minutes per high-resolution volumetric image.},
author = {Suzani, Amin and Rasoulian, Abtin and Seitel, Alexander and Fels, Sidney and Rohling, Robert N. and Abolmaesumi, Purang},
booktitle = {Medical Imaging 2015: Image-Guided Procedures, Robotic Interventions, and Modeling},
doi = {10.1117/12.2081542},
isbn = {9781628415056},
issn = {1605-7422},
title = {{Deep learning for automatic localization, identification, and segmentation of vertebral bodies in volumetric MR images}},
year = {2015}
}

@inproceedings{Korez2016,
abstract = {We propose an automated method for supervised segmentation of vertebral bodies (VBs) from three-dimensional (3D) magnetic resonance (MR) spine images that is based on coupling deformable models with convolutional neural networks (CNNs). We designed a 3D CNN architecture that learns the appearance from a training set of VBs to generate 3D spatial VB probability maps,which guide deformable models towards VB boundaries. The proposed method was applied to segment 161 VBs from 3D MR spine images of 23 subjects,and the results were compared to reference segmentations. By yielding an overall Dice similarity coefficient of 93.4±1.7{\%},mean symmetric surface distance of 0.54±0.14mm and Hausdorff distance of 3.83±1.04 mm,the proposed method proved superior to existing VB segmentation methods.},
author = {Korez, Robert and Likar, Bo{\v{s}}tjan and Pernu{\v{s}}, Franjo and Vrtovec, Toma{\v{z}}},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-46723-8_50},
isbn = {9783319467221},
issn = {16113349},
title = {{Model-based segmentation of vertebral bodies from MR images with 3D CNNS}},
year = {2016}
}


@inproceedings{Janssens2018,
abstract = {We present a method to address the challenging problem of segmentation of lumbar vertebrae from CT images acquired with varying fields of view. Our method is based on cascaded 3D Fully Convolutional Networks (FCNs) consisting of a localization FCN and a segmentation FCN. More specifically, in the first step we train a regression 3D FCN (we call it 'LocalizationNet') to find the bounding box of the lumbar region. After that, a 3D U-net like FCN (we call it 'Segmentation-Net') is then developed, which after training, can perform a pixel-wise multi-class segmentation to map a cropped lumber region volumetric data to its volume-wise labels. Evaluated on publicly available datasets, our method achieved an average Dice coefficient of 95.77 ± 0.81{\%} and an average symmetric surface distance of 0.37 ± 0.06 mm.},
archivePrefix = {arXiv},
arxivId = {1712.01509},
author = {Janssens, Rens and Zeng, Guodong and Zheng, Guoyan},
booktitle = {Proceedings - International Symposium on Biomedical Imaging},
doi = {10.1109/ISBI.2018.8363715},
eprint = {1712.01509},
isbn = {9781538636367},
issn = {19458452},
keywords = {CT,Fully Convolutional Networks,Lumbar vertebrae,Segmentation},
title = {{Fully automatic segmentation of lumbar vertebrae from CT images using cascaded 3D fully convolutional networks}},
year = {2018}
}


@inproceedings{Sekuboyina2018,
abstract = {Accurate segmentation of the spine in computed tomography (CT) images is mandatory for quantitative analysis, e.g. in osteoporosis, but remains challenging due to high variability in vertebral morphology and spinal anatomy among patients. Conventionally, spine segmentation was performed by model-based techniques employing spine atlases or statistical shape models. We argue that such approaches, even though intuitive, fail to address clinical abnormalities such as vertebral fractures, scoliosis, etc. We propose a novel deep learning-based method for segmenting the spine, which does not rely on any pre-defined shape model. We employ two networks: one for localisation and another for segmentation. Since a typical spine CT scan cannot be processed at once owing to its large dimensions, we find that both nets are essential to work towards a perfect segmentation. We evaluate our framework on three datasets containing healthy and fractured cases: two private and one public. Our approach achieves a mean Dice coefficient of {\~{}}0.87, which is comparable but not higher than the state-of-art model-based approaches. However, we show that our approach handles degenerate cases more accurately.},
author = {Sekuboyina, Anjany and Kuka{\v{c}}ka, Jan and Kirschke, Jan S. and Menze, Bjoern H. and Valentinitsch, Alexander},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-74113-0_10},
isbn = {9783319741123},
issn = {16113349},
keywords = {Automated segmentation,Deep learning,Fully convolutional network,Spine segmentation},
title = {{Attention-driven deep learning for pathological spine segmentation}},
year = {2018}
}


@inproceedings{Payer2020,
abstract = {Localization and segmentation of vertebral bodies from spine CT volumes are crucial for pathological diagnosis, surgical planning, and postoperative assessment. However, fully automatic analysis of spine CT volumes is difficult due to the anatomical variation of pathologies, noise caused by screws and implants, and the large range of different field-of-views. We propose a fully automatic coarse to fine approach for vertebrae localization and segmentation based on fully convolutional CNNs. In a three-step approach, at first, a U-Net localizes the rough position of the spine. Then, the SpatialConfiguration-Net performs vertebrae localization and identification using heatmap regression. Finally, a U-Net performs binary segmentation of each identified vertebrae in a high resolution, before merging the individual predictions into the resulting multi-label vertebrae segmentation. The evaluation shows top performance of our approach, ranking first place and winning the MICCAI 2019 Large Scale Vertebrae Segmentation Challenge (VerSe 2019).},
author = {Payer, Christian and {\v{S}}tern, Darko and Bischof, Horst and Urschler, Martin},
booktitle = {VISIGRAPP 2020 - Proceedings of the 15th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
doi = {10.5220/0008975201240133},
isbn = {9789897584022},
keywords = {SpatialConfiguration-Net,U-Net,VerSe 2019 Challenge,Vertebrae Localization,Vertebrae Segmentation},
title = {{Coarse to fine vertebrae localization and segmentation with spatialconfiguration-Net and U-Net}},
year = {2020}
}


@article{Lessmann2019,
abstract = {Precise segmentation and anatomical identification of the vertebrae provides the basis for automatic analysis of the spine, such as detection of vertebral compression fractures or other abnormalities. Most dedicated spine CT and MR scans as well as scans of the chest, abdomen or neck cover only part of the spine. Segmentation and identification should therefore not rely on the visibility of certain vertebrae or a certain number of vertebrae. We propose an iterative instance segmentation approach that uses a fully convolutional neural network to segment and label vertebrae one after the other, independently of the number of visible vertebrae. This instance-by-instance segmentation is enabled by combining the network with a memory component that retains information about already segmented vertebrae. The network iteratively analyzes image patches, using information from both image and memory to search for the next vertebra. To efficiently traverse the image, we include the prior knowledge that the vertebrae are always located next to each other, which is used to follow the vertebral column. The network concurrently performs multiple tasks, which are segmentation of a vertebra, regression of its anatomical label and prediction whether the vertebra is completely visible in the image, which allows to exclude incompletely visible vertebrae from further analyses. The predicted anatomical labels of the individual vertebrae are additionally refined with a maximum likelihood approach, choosing the overall most likely labeling if all detected vertebrae are taken into account. This method was evaluated with five diverse datasets, including multiple modalities (CT and MR), various fields of view and coverages of different sections of the spine, and a particularly challenging set of low-dose chest CT scans. For vertebra segmentation, the average Dice score was 94.9 ± 2.1{\%} with an average absolute symmetric surface distance of 0.2 ± 10.1mm. The anatomical identification had an accuracy of 93{\%}, corresponding to a single case with mislabeled vertebrae. Vertebrae were classified as completely or incompletely visible with an accuracy of 97{\%}. The proposed iterative segmentation method compares favorably with state-of-the-art methods and is fast, flexible and generalizable.},
archivePrefix = {arXiv},
arxivId = {1804.04383},
author = {Lessmann, Nikolas and van Ginneken, Bram and de Jong, Pim A. and I{\v{s}}gum, Ivana},
doi = {10.1016/j.media.2019.02.005},
eprint = {1804.04383},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Deep learning,Iterative instance segmentation,Vertebra identification,Vertebra segmentation},
pmid = {30771712},
title = {{Iterative fully convolutional neural networks for automatic vertebra segmentation and identification}},
year = {2019}
}
