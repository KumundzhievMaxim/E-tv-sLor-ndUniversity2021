\chapter{Models Background}
\label{ch:model_background}

\section{Gentle introduction}
In this particular paragraph we will deliberate the proposed model background and its main dissemblance from general unet architecture.

Jointly the solution it was utilized 2 convolution networks with same architectures but sundry purposes and parameters. By scenario firstly it is issued detection model afterwards identification model. The detection model comes up with segmenting of vertebra from background. Whereas the identification model identifies what vertebrates belong which segmented pixels. To fine it down the identification model does not categorize each pixel in discrete manner, vice continuously produce value which subsequently is rounded correspondingly to a specific vertebra. It worth to mention inwardly full solution captures both short-range and long range information. Short-range information is retrieved utilizing detection model. The identification model is trained by feeding in large slices which capture long-range information which is essential for the task of identifying individual vertebrae. Acquisition of final results is done by multiplying detection and identification models results to elaborate labels on each pixel afterwards aggregating them to produce final centroid estimates for each vertebra.

The step by step representation in terms of visualisation is demonstrated on the figure \ref{fig:detection_identification_steps}.

\begin{figure}[h]
    \centering \includegraphics[width=9cm]{images/detection_identification_steps.png}
    \caption {(a) shows an original scan in grey-scale, (b) shows the output of the detection model applied to the scan, (c) shows the output of the identification model applied to the scan, (d) shows (b) and (c) multiplied together to produce a final prediction for each pixel.}
    \label{fig:detection_identification_steps}
\end{figure}

\section{Detection Model}
As previously mentioned detection model \ref{fig:detection_model} comes up with segmenting of vertebra from background. Taking it closer into consideration the model classifies each dedicated pixel of scan whether it is background or vertebrae. Jointly the initialization of weights it was  defined such as the background label with 0.1 weighting and the vertebrae label with 0.9 weighting. It was thought-out to repeal the fraction of nature background state at particular scan. As for loss function it was consumed \cite{Zhang2018} weighted categorical cross entropy with 2 classes, depicted as:
\begin{align*}
 L(P, Q) = 0.1 P(0)\log Q(0) + 0.9P(1)\log Q(1)
\end{align*}
where P, Q - particular distributions 

Unlike standard unet architecture it was used same padding for all convolutional layers with stride 1, a learning rate
$\lambda$ of 0.001, a batch size of 16 and batch normalization after every convolutional layer with momentum of 0.1. The model implementation can be found on \href{https://github.com/KumundzhievMaxim/VertebraeSegmentation/blob/main/train_detection_model.py}{\color{blue} github project repository}. 

\begin{figure}[h]
    \centering \includegraphics[width=9cm]{images/detection_model.png}
    \caption {Detection Model Architecture}
    \label{fig:detection_model}
\end{figure}
 
\section{Identification Model}
By the previous description identification model \ref{fig:identification_model} identifies what vertebrates belong which segmented pixels. For what it was established unet-wise architecture with revamped parameters. Updates brought changes of input layer channels number which corresponds to 8 to pass in samples of size $8x80x320$. The introduced filters sized $5x20$ at the lowest level of the architecture  increases the size of the receptive field thereby maximizing the potential information retrieved by the network. To clarify, the background pixels are strained out, denoting just that pixels which are labeled as background when we train model. As for loss function the following modified L1 function was approached:
\begin{align*}
 L = \begin{cases} \lvert y_i - x_i \rvert\ \mbox{if } x\mbox{$\neq 0$} \\ 0, \mbox{ otherwise} \end{cases}
\end{align*}
where $y_i$ - predicted value of pixel $i$ and $x_i$ - true value of pixel $i$.
Unlike standard unet architecture it was used same padding for all convolutional layers with stride 1, a learning rate
$\lambda$ of 0.001, a batch size of 32 and batch normalization after every convolutional layer with momentum of 0.1. The model implementation can be found on \href{https://github.com/KumundzhievMaxim/VertebraeSegmentation/blob/main/train_identification_model.py}{\color{blue} github project repository}.

\begin{figure}[h]
    \centering \includegraphics[width=9cm]{images/identification_model.png}
    \caption {Identification Model Architecture}
    \label{fig:identification_model}
\end{figure}

The identification model outputs a continuous value for each pixel of a scan which, is rounded to an integer to correspond to a specific vertebrae. The identification model gives a value to each pixel even if that pixel is not depicting any vertebrae and is a background. These pixels will be filtered out of the final
predictions by multiplying them by their corresponding pixel from the output of the detection model which should be 0 for a background pixel. The model outputs are represented as continuous value for each dedicated pixel of particular scan which further is rounded to correspond to a specific vertebrae integer. As well it should be considered the model award each pixel's value nay it is background and does not represent any vertebrae. Even though these pixels will be filtered out of the final predictions by multiplying them by their corresponding pixel from the output of the detection model which should be 0 for a background pixel.

