\chapter{Problem Background}
\label{ch:problem_background}
As well, jointly the thesis I was willing to develop a neural net model for automatic spine vertebrae segmentation of computer tomography scans (images). CT is a preferred image modality to examine the bone part of a spine due to high bone-to-soft-tissue contrast. As I learned, before proceeding with analysing the bones themselves we need to precisely reconstruct and label our data. Owing to \href{https://biomedia.doc.ic.ac.uk/}{\color{blue}"BioMediaA"} laboratory I was capable to use already collected and labeled dataset. Within this chapter I will reflect explicit route of research work accomplished from 2015 to nowadays in terms of vertebral labelling and segmentation.            

\section{Vertebral Segmentation}
Commonly, for vertebral segmentation it was utilized techniques, which naturally comprised aligning a shape-prior to the spine and deforming it such that it fits the given spine. For that it was used geometrical models,  statistical shape models and active contours. But with advent of neural networks and rising of computational power we started developing more complex nets architectures and tune more hyper parameters of them rather than focus on the images and developing a new shape-prior algorithms. 

Thus, neural networks can often find patterns and shapes on the images which frequently scientists can not manage with. Yes, we still need to control the neural net as well as interpret the output, but as for now almost all creative work can be handled by the various net architectures.

As an argument I can consider Amin Suzani et al. work \cite{Suzani2015} who proposed to use a multi-layer perceptron to detect the vertebral bodies and employ deformable registration for segmentation. Robert Korez et al. \cite{Korez2016} in work "Model-based segmentation of vertebral bodies from MR images with 3d CNNs" had achieved high accuracy predicting probability maps, which are then used to guide the boundaries of a deformable vertebral model making use of a 3D convolutional neural networks (CNN). 

Moving forward more and more with data-driven decisions, Anjany Sekuboyina et al. \cite{Sekuboyina2018} had established a patch-based binary segmentation of the spine using a U-Net, followed by denoising the spine mask using a low-resolution heat map.

At 2018, Rens Janssens, Guodong Zeng, and Guoyan Zheng \cite{Janssens2018} had successfully performed multi-class segmentation of lumbar vertebrae with two successive CNNs. In the same time at 2018, Nikolas Lessmann et al. \cite{Lessmann2019} had firstly introduced a two-staged iterative approach, wherein the first stage involves identifying and segmenting one vertebrae after another at a lower resolution, followed a second CNN for refining the lower-resolution masks. Enhancing approach, Nikolas Lessmann et al. \cite{Lessmann2019} had proposed a single stage FCN which iteratively regresses the vertebraeâ€™s anatomical label and segments it. Once the entire scan is segmented, the vertebral labels adjusted using a maximum likelihood
technique. 

Eventually, the replacement of Nikolas Lessmann et al. 1-stage and 2-stage iterative solutions and Anjany Sekuboyina et al. patch-wise U-net, at 2020 Christian Payer et al. \cite{Payer2020} had released a coarse-to-fine approach involving three stages, spine localisation, vertebra labelling, and vertebrae segmentation, all three utilising purposefully designed FCNs.

\section{Vertebral Labeling}
Aside vertebral segmentation topic, still crucial is to label any particular image or entire data set. Doing so, it worth to take into consideration it is not the simplest and the cheapest task. Of course we can label (annotate) images by ourselves. But for such purposes you need to find appropriate tooling as well as the time. Besides manual approaches scientist always were willing to automate labelling (annotation) process. At the beginning it was given a try with classical deformable shape-or-pose-models which explicitly described in "Segmentation of pathological structures by landmark-assisted deformable models" \cite{Ibragimov2017} work. As well as there were experiments with Haar-like features to identify vertebrae using random forest regression voting, described in \cite{Bromiley2016} by Paul A. Bromiley et al.

Changing the direction and proceeding fully convolutional and regressing on input-sized heat map responses instead of directly learning the centroid locations, at 2017 Dong Yang et al. established DI2IN architecture \cite{Yang2017} which was proposed for heat map regression of the vertebral centroids at lower resolution. 

Lastly, a huge impact was brought in by Christian Payer et al. with work "Automatic vertebra labeling in large-scale 3D CT using deep image-to-image network with message passing and sparsity regularization" \cite{Payer2019} what allowed to process the integrating of global context and local detail in one end-to-end trainable network within two-stream architecture so called spatial-configuration net. 



